{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IRIS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width         species\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df_features = df[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "scaler = StandardScaler()\n",
    "df_features = scaler.fit_transform(X=df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "df_targets = df.species.to_numpy().reshape(-1,1)\n",
    "df_targets = encoder.fit_transform(df_targets)\n",
    "df_targets = df_targets.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features,df_targets, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimData = X_train.shape[1]\n",
    "nClasses = y_train.shape[1]\n",
    "advanced_act = LeakyReLU(alpha=.003)\n",
    "model_reg = Sequential()\n",
    "model_reg.add(Dense(10, activation= advanced_act , input_shape=(dimData,)))\n",
    "model_reg.add(Dense(nClasses, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(4, 10) dtype=float32, numpy=\n",
       " array([[ 0.44230127,  0.5729337 , -0.24559423, -0.36545086,  0.27700955,\n",
       "          0.26781934, -0.24273217,  0.3047014 , -0.03533393, -0.3197533 ],\n",
       "        [-0.4455716 ,  0.13795555,  0.30701673,  0.24140358, -0.16314521,\n",
       "         -0.31981274, -0.0797466 , -0.5262332 ,  0.1810556 ,  0.48984122],\n",
       "        [ 0.55108106, -0.5739311 ,  0.47795558, -0.32678336,  0.40033817,\n",
       "          0.03785479,  0.57672036,  0.25136548,  0.09317493,  0.56006646],\n",
       "        [-0.30832016,  0.19936633, -0.2513911 , -0.09058195,  0.45730054,\n",
       "          0.42056644,  0.44070625,  0.0178231 ,  0.57962537,  0.09154826]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(10, 3) dtype=float32, numpy=\n",
       " array([[ 0.31085086,  0.3658247 ,  0.12327933],\n",
       "        [-0.21653011, -0.2692    , -0.53954244],\n",
       "        [-0.5036988 ,  0.14036608, -0.23971969],\n",
       "        [-0.0977397 , -0.5609263 ,  0.23545718],\n",
       "        [-0.53948736, -0.12486506, -0.38154727],\n",
       "        [ 0.23499703,  0.14230251,  0.0521009 ],\n",
       "        [-0.2953814 , -0.00589585,  0.5364835 ],\n",
       "        [-0.12546974, -0.64768374, -0.3877112 ],\n",
       "        [ 0.25421453,  0.01508671,  0.08741498],\n",
       "        [ 0.14990407, -0.52668154, -0.5673672 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 - 0s - loss: 1.1079 - accuracy: 0.2200 - val_loss: 1.0895 - val_accuracy: 0.2600\n",
      "Epoch 2/500\n",
      "1/1 - 0s - loss: 1.1027 - accuracy: 0.2300 - val_loss: 1.0843 - val_accuracy: 0.3000\n",
      "Epoch 3/500\n",
      "1/1 - 0s - loss: 1.0975 - accuracy: 0.2600 - val_loss: 1.0791 - val_accuracy: 0.3200\n",
      "Epoch 4/500\n",
      "1/1 - 0s - loss: 1.0924 - accuracy: 0.2900 - val_loss: 1.0740 - val_accuracy: 0.3800\n",
      "Epoch 5/500\n",
      "1/1 - 0s - loss: 1.0874 - accuracy: 0.3000 - val_loss: 1.0690 - val_accuracy: 0.3800\n",
      "Epoch 6/500\n",
      "1/1 - 0s - loss: 1.0825 - accuracy: 0.3000 - val_loss: 1.0640 - val_accuracy: 0.3800\n",
      "Epoch 7/500\n",
      "1/1 - 0s - loss: 1.0776 - accuracy: 0.3100 - val_loss: 1.0591 - val_accuracy: 0.4000\n",
      "Epoch 8/500\n",
      "1/1 - 0s - loss: 1.0728 - accuracy: 0.3200 - val_loss: 1.0542 - val_accuracy: 0.4000\n",
      "Epoch 9/500\n",
      "1/1 - 0s - loss: 1.0681 - accuracy: 0.3200 - val_loss: 1.0495 - val_accuracy: 0.4000\n",
      "Epoch 10/500\n",
      "1/1 - 0s - loss: 1.0634 - accuracy: 0.3200 - val_loss: 1.0448 - val_accuracy: 0.4200\n",
      "Epoch 11/500\n",
      "1/1 - 0s - loss: 1.0587 - accuracy: 0.3400 - val_loss: 1.0401 - val_accuracy: 0.4400\n",
      "Epoch 12/500\n",
      "1/1 - 0s - loss: 1.0542 - accuracy: 0.3400 - val_loss: 1.0355 - val_accuracy: 0.4200\n",
      "Epoch 13/500\n",
      "1/1 - 0s - loss: 1.0497 - accuracy: 0.3600 - val_loss: 1.0310 - val_accuracy: 0.4600\n",
      "Epoch 14/500\n",
      "1/1 - 0s - loss: 1.0453 - accuracy: 0.3600 - val_loss: 1.0265 - val_accuracy: 0.4600\n",
      "Epoch 15/500\n",
      "1/1 - 0s - loss: 1.0409 - accuracy: 0.3700 - val_loss: 1.0221 - val_accuracy: 0.4600\n",
      "Epoch 16/500\n",
      "1/1 - 0s - loss: 1.0367 - accuracy: 0.3700 - val_loss: 1.0177 - val_accuracy: 0.4600\n",
      "Epoch 17/500\n",
      "1/1 - 0s - loss: 1.0325 - accuracy: 0.3700 - val_loss: 1.0134 - val_accuracy: 0.4600\n",
      "Epoch 18/500\n",
      "1/1 - 0s - loss: 1.0283 - accuracy: 0.3700 - val_loss: 1.0092 - val_accuracy: 0.4800\n",
      "Epoch 19/500\n",
      "1/1 - 0s - loss: 1.0242 - accuracy: 0.3700 - val_loss: 1.0050 - val_accuracy: 0.5000\n",
      "Epoch 20/500\n",
      "1/1 - 0s - loss: 1.0202 - accuracy: 0.3800 - val_loss: 1.0009 - val_accuracy: 0.5000\n",
      "Epoch 21/500\n",
      "1/1 - 0s - loss: 1.0162 - accuracy: 0.3900 - val_loss: 0.9968 - val_accuracy: 0.4800\n",
      "Epoch 22/500\n",
      "1/1 - 0s - loss: 1.0122 - accuracy: 0.3900 - val_loss: 0.9928 - val_accuracy: 0.4800\n",
      "Epoch 23/500\n",
      "1/1 - 0s - loss: 1.0083 - accuracy: 0.4100 - val_loss: 0.9888 - val_accuracy: 0.4800\n",
      "Epoch 24/500\n",
      "1/1 - 0s - loss: 1.0044 - accuracy: 0.4000 - val_loss: 0.9848 - val_accuracy: 0.4800\n",
      "Epoch 25/500\n",
      "1/1 - 0s - loss: 1.0006 - accuracy: 0.4100 - val_loss: 0.9808 - val_accuracy: 0.4800\n",
      "Epoch 26/500\n",
      "1/1 - 0s - loss: 0.9968 - accuracy: 0.4200 - val_loss: 0.9769 - val_accuracy: 0.4800\n",
      "Epoch 27/500\n",
      "1/1 - 0s - loss: 0.9931 - accuracy: 0.4300 - val_loss: 0.9729 - val_accuracy: 0.4800\n",
      "Epoch 28/500\n",
      "1/1 - 0s - loss: 0.9894 - accuracy: 0.4300 - val_loss: 0.9691 - val_accuracy: 0.5000\n",
      "Epoch 29/500\n",
      "1/1 - 0s - loss: 0.9857 - accuracy: 0.4300 - val_loss: 0.9652 - val_accuracy: 0.5200\n",
      "Epoch 30/500\n",
      "1/1 - 0s - loss: 0.9821 - accuracy: 0.4300 - val_loss: 0.9614 - val_accuracy: 0.5200\n",
      "Epoch 31/500\n",
      "1/1 - 0s - loss: 0.9785 - accuracy: 0.4400 - val_loss: 0.9576 - val_accuracy: 0.5200\n",
      "Epoch 32/500\n",
      "1/1 - 0s - loss: 0.9750 - accuracy: 0.4600 - val_loss: 0.9539 - val_accuracy: 0.5200\n",
      "Epoch 33/500\n",
      "1/1 - 0s - loss: 0.9714 - accuracy: 0.4600 - val_loss: 0.9501 - val_accuracy: 0.5200\n",
      "Epoch 34/500\n",
      "1/1 - 0s - loss: 0.9679 - accuracy: 0.4700 - val_loss: 0.9464 - val_accuracy: 0.5400\n",
      "Epoch 35/500\n",
      "1/1 - 0s - loss: 0.9645 - accuracy: 0.4700 - val_loss: 0.9427 - val_accuracy: 0.5400\n",
      "Epoch 36/500\n",
      "1/1 - 0s - loss: 0.9610 - accuracy: 0.4900 - val_loss: 0.9391 - val_accuracy: 0.5400\n",
      "Epoch 37/500\n",
      "1/1 - 0s - loss: 0.9576 - accuracy: 0.4900 - val_loss: 0.9354 - val_accuracy: 0.5400\n",
      "Epoch 38/500\n",
      "1/1 - 0s - loss: 0.9542 - accuracy: 0.5000 - val_loss: 0.9318 - val_accuracy: 0.5400\n",
      "Epoch 39/500\n",
      "1/1 - 0s - loss: 0.9508 - accuracy: 0.5000 - val_loss: 0.9282 - val_accuracy: 0.5400\n",
      "Epoch 40/500\n",
      "1/1 - 0s - loss: 0.9474 - accuracy: 0.5000 - val_loss: 0.9246 - val_accuracy: 0.5600\n",
      "Epoch 41/500\n",
      "1/1 - 0s - loss: 0.9441 - accuracy: 0.5000 - val_loss: 0.9211 - val_accuracy: 0.5800\n",
      "Epoch 42/500\n",
      "1/1 - 0s - loss: 0.9407 - accuracy: 0.5100 - val_loss: 0.9176 - val_accuracy: 0.6000\n",
      "Epoch 43/500\n",
      "1/1 - 0s - loss: 0.9374 - accuracy: 0.5200 - val_loss: 0.9141 - val_accuracy: 0.6200\n",
      "Epoch 44/500\n",
      "1/1 - 0s - loss: 0.9342 - accuracy: 0.5200 - val_loss: 0.9106 - val_accuracy: 0.6200\n",
      "Epoch 45/500\n",
      "1/1 - 0s - loss: 0.9309 - accuracy: 0.5300 - val_loss: 0.9071 - val_accuracy: 0.6200\n",
      "Epoch 46/500\n",
      "1/1 - 0s - loss: 0.9276 - accuracy: 0.5400 - val_loss: 0.9036 - val_accuracy: 0.6200\n",
      "Epoch 47/500\n",
      "1/1 - 0s - loss: 0.9244 - accuracy: 0.5400 - val_loss: 0.9001 - val_accuracy: 0.6400\n",
      "Epoch 48/500\n",
      "1/1 - 0s - loss: 0.9211 - accuracy: 0.5400 - val_loss: 0.8966 - val_accuracy: 0.6400\n",
      "Epoch 49/500\n",
      "1/1 - 0s - loss: 0.9179 - accuracy: 0.5400 - val_loss: 0.8931 - val_accuracy: 0.7000\n",
      "Epoch 50/500\n",
      "1/1 - 0s - loss: 0.9147 - accuracy: 0.5500 - val_loss: 0.8896 - val_accuracy: 0.7000\n",
      "Epoch 51/500\n",
      "1/1 - 0s - loss: 0.9115 - accuracy: 0.5500 - val_loss: 0.8861 - val_accuracy: 0.7000\n",
      "Epoch 52/500\n",
      "1/1 - 0s - loss: 0.9083 - accuracy: 0.5800 - val_loss: 0.8827 - val_accuracy: 0.7000\n",
      "Epoch 53/500\n",
      "1/1 - 0s - loss: 0.9051 - accuracy: 0.5900 - val_loss: 0.8792 - val_accuracy: 0.7000\n",
      "Epoch 54/500\n",
      "1/1 - 0s - loss: 0.9019 - accuracy: 0.5900 - val_loss: 0.8758 - val_accuracy: 0.7000\n",
      "Epoch 55/500\n",
      "1/1 - 0s - loss: 0.8987 - accuracy: 0.5900 - val_loss: 0.8723 - val_accuracy: 0.7200\n",
      "Epoch 56/500\n",
      "1/1 - 0s - loss: 0.8955 - accuracy: 0.5900 - val_loss: 0.8688 - val_accuracy: 0.7200\n",
      "Epoch 57/500\n",
      "1/1 - 0s - loss: 0.8923 - accuracy: 0.6000 - val_loss: 0.8653 - val_accuracy: 0.7400\n",
      "Epoch 58/500\n",
      "1/1 - 0s - loss: 0.8890 - accuracy: 0.6000 - val_loss: 0.8618 - val_accuracy: 0.7400\n",
      "Epoch 59/500\n",
      "1/1 - 0s - loss: 0.8858 - accuracy: 0.6400 - val_loss: 0.8584 - val_accuracy: 0.7600\n",
      "Epoch 60/500\n",
      "1/1 - 0s - loss: 0.8825 - accuracy: 0.6500 - val_loss: 0.8549 - val_accuracy: 0.7600\n",
      "Epoch 61/500\n",
      "1/1 - 0s - loss: 0.8793 - accuracy: 0.6600 - val_loss: 0.8513 - val_accuracy: 0.7600\n",
      "Epoch 62/500\n",
      "1/1 - 0s - loss: 0.8760 - accuracy: 0.6800 - val_loss: 0.8478 - val_accuracy: 0.7600\n",
      "Epoch 63/500\n",
      "1/1 - 0s - loss: 0.8727 - accuracy: 0.6800 - val_loss: 0.8443 - val_accuracy: 0.7600\n",
      "Epoch 64/500\n",
      "1/1 - 0s - loss: 0.8694 - accuracy: 0.6800 - val_loss: 0.8408 - val_accuracy: 0.7400\n",
      "Epoch 65/500\n",
      "1/1 - 0s - loss: 0.8661 - accuracy: 0.6800 - val_loss: 0.8372 - val_accuracy: 0.7400\n",
      "Epoch 66/500\n",
      "1/1 - 0s - loss: 0.8628 - accuracy: 0.6900 - val_loss: 0.8337 - val_accuracy: 0.7400\n",
      "Epoch 67/500\n",
      "1/1 - 0s - loss: 0.8595 - accuracy: 0.6900 - val_loss: 0.8302 - val_accuracy: 0.7400\n",
      "Epoch 68/500\n",
      "1/1 - 0s - loss: 0.8561 - accuracy: 0.6900 - val_loss: 0.8266 - val_accuracy: 0.7400\n",
      "Epoch 69/500\n",
      "1/1 - 0s - loss: 0.8528 - accuracy: 0.7100 - val_loss: 0.8230 - val_accuracy: 0.7400\n",
      "Epoch 70/500\n",
      "1/1 - 0s - loss: 0.8494 - accuracy: 0.7100 - val_loss: 0.8193 - val_accuracy: 0.7400\n",
      "Epoch 71/500\n",
      "1/1 - 0s - loss: 0.8460 - accuracy: 0.7100 - val_loss: 0.8157 - val_accuracy: 0.7400\n",
      "Epoch 72/500\n",
      "1/1 - 0s - loss: 0.8427 - accuracy: 0.7100 - val_loss: 0.8120 - val_accuracy: 0.7400\n",
      "Epoch 73/500\n",
      "1/1 - 0s - loss: 0.8393 - accuracy: 0.7100 - val_loss: 0.8083 - val_accuracy: 0.7400\n",
      "Epoch 74/500\n",
      "1/1 - 0s - loss: 0.8359 - accuracy: 0.7200 - val_loss: 0.8046 - val_accuracy: 0.7400\n",
      "Epoch 75/500\n",
      "1/1 - 0s - loss: 0.8325 - accuracy: 0.7300 - val_loss: 0.8009 - val_accuracy: 0.7400\n",
      "Epoch 76/500\n",
      "1/1 - 0s - loss: 0.8291 - accuracy: 0.7400 - val_loss: 0.7972 - val_accuracy: 0.7600\n",
      "Epoch 77/500\n",
      "1/1 - 0s - loss: 0.8257 - accuracy: 0.7400 - val_loss: 0.7934 - val_accuracy: 0.8000\n",
      "Epoch 78/500\n",
      "1/1 - 0s - loss: 0.8223 - accuracy: 0.7800 - val_loss: 0.7897 - val_accuracy: 0.8000\n",
      "Epoch 79/500\n",
      "1/1 - 0s - loss: 0.8188 - accuracy: 0.8000 - val_loss: 0.7860 - val_accuracy: 0.8200\n",
      "Epoch 80/500\n",
      "1/1 - 0s - loss: 0.8154 - accuracy: 0.8000 - val_loss: 0.7823 - val_accuracy: 0.8200\n",
      "Epoch 81/500\n",
      "1/1 - 0s - loss: 0.8120 - accuracy: 0.8000 - val_loss: 0.7786 - val_accuracy: 0.8200\n",
      "Epoch 82/500\n",
      "1/1 - 0s - loss: 0.8086 - accuracy: 0.8000 - val_loss: 0.7748 - val_accuracy: 0.8400\n",
      "Epoch 83/500\n",
      "1/1 - 0s - loss: 0.8051 - accuracy: 0.8000 - val_loss: 0.7711 - val_accuracy: 0.8600\n",
      "Epoch 84/500\n",
      "1/1 - 0s - loss: 0.8017 - accuracy: 0.8100 - val_loss: 0.7673 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "1/1 - 0s - loss: 0.7982 - accuracy: 0.8200 - val_loss: 0.7636 - val_accuracy: 0.8600\n",
      "Epoch 86/500\n",
      "1/1 - 0s - loss: 0.7948 - accuracy: 0.8200 - val_loss: 0.7599 - val_accuracy: 0.8600\n",
      "Epoch 87/500\n",
      "1/1 - 0s - loss: 0.7914 - accuracy: 0.8300 - val_loss: 0.7562 - val_accuracy: 0.8600\n",
      "Epoch 88/500\n",
      "1/1 - 0s - loss: 0.7880 - accuracy: 0.8300 - val_loss: 0.7525 - val_accuracy: 0.8600\n",
      "Epoch 89/500\n",
      "1/1 - 0s - loss: 0.7845 - accuracy: 0.8400 - val_loss: 0.7487 - val_accuracy: 0.8600\n",
      "Epoch 90/500\n",
      "1/1 - 0s - loss: 0.7811 - accuracy: 0.8400 - val_loss: 0.7450 - val_accuracy: 0.8600\n",
      "Epoch 91/500\n",
      "1/1 - 0s - loss: 0.7777 - accuracy: 0.8400 - val_loss: 0.7413 - val_accuracy: 0.8600\n",
      "Epoch 92/500\n",
      "1/1 - 0s - loss: 0.7743 - accuracy: 0.8400 - val_loss: 0.7375 - val_accuracy: 0.8600\n",
      "Epoch 93/500\n",
      "1/1 - 0s - loss: 0.7709 - accuracy: 0.8400 - val_loss: 0.7338 - val_accuracy: 0.8600\n",
      "Epoch 94/500\n",
      "1/1 - 0s - loss: 0.7675 - accuracy: 0.8400 - val_loss: 0.7301 - val_accuracy: 0.8600\n",
      "Epoch 95/500\n",
      "1/1 - 0s - loss: 0.7641 - accuracy: 0.8400 - val_loss: 0.7264 - val_accuracy: 0.8600\n",
      "Epoch 96/500\n",
      "1/1 - 0s - loss: 0.7606 - accuracy: 0.8400 - val_loss: 0.7227 - val_accuracy: 0.8600\n",
      "Epoch 97/500\n",
      "1/1 - 0s - loss: 0.7572 - accuracy: 0.8400 - val_loss: 0.7190 - val_accuracy: 0.8600\n",
      "Epoch 98/500\n",
      "1/1 - 0s - loss: 0.7537 - accuracy: 0.8600 - val_loss: 0.7153 - val_accuracy: 0.8600\n",
      "Epoch 99/500\n",
      "1/1 - 0s - loss: 0.7503 - accuracy: 0.8700 - val_loss: 0.7116 - val_accuracy: 0.8600\n",
      "Epoch 100/500\n",
      "1/1 - 0s - loss: 0.7468 - accuracy: 0.8700 - val_loss: 0.7080 - val_accuracy: 0.8400\n",
      "Epoch 101/500\n",
      "1/1 - 0s - loss: 0.7434 - accuracy: 0.8700 - val_loss: 0.7043 - val_accuracy: 0.8400\n",
      "Epoch 102/500\n",
      "1/1 - 0s - loss: 0.7400 - accuracy: 0.8700 - val_loss: 0.7006 - val_accuracy: 0.8400\n",
      "Epoch 103/500\n",
      "1/1 - 0s - loss: 0.7365 - accuracy: 0.8700 - val_loss: 0.6970 - val_accuracy: 0.8400\n",
      "Epoch 104/500\n",
      "1/1 - 0s - loss: 0.7331 - accuracy: 0.8700 - val_loss: 0.6933 - val_accuracy: 0.8600\n",
      "Epoch 105/500\n",
      "1/1 - 0s - loss: 0.7296 - accuracy: 0.8700 - val_loss: 0.6896 - val_accuracy: 0.8600\n",
      "Epoch 106/500\n",
      "1/1 - 0s - loss: 0.7262 - accuracy: 0.8800 - val_loss: 0.6859 - val_accuracy: 0.8600\n",
      "Epoch 107/500\n",
      "1/1 - 0s - loss: 0.7227 - accuracy: 0.8800 - val_loss: 0.6823 - val_accuracy: 0.8600\n",
      "Epoch 108/500\n",
      "1/1 - 0s - loss: 0.7193 - accuracy: 0.8800 - val_loss: 0.6786 - val_accuracy: 0.8600\n",
      "Epoch 109/500\n",
      "1/1 - 0s - loss: 0.7158 - accuracy: 0.8800 - val_loss: 0.6750 - val_accuracy: 0.8600\n",
      "Epoch 110/500\n",
      "1/1 - 0s - loss: 0.7124 - accuracy: 0.8900 - val_loss: 0.6714 - val_accuracy: 0.8600\n",
      "Epoch 111/500\n",
      "1/1 - 0s - loss: 0.7090 - accuracy: 0.8900 - val_loss: 0.6678 - val_accuracy: 0.8600\n",
      "Epoch 112/500\n",
      "1/1 - 0s - loss: 0.7056 - accuracy: 0.8900 - val_loss: 0.6642 - val_accuracy: 0.8600\n",
      "Epoch 113/500\n",
      "1/1 - 0s - loss: 0.7021 - accuracy: 0.8900 - val_loss: 0.6606 - val_accuracy: 0.8600\n",
      "Epoch 114/500\n",
      "1/1 - 0s - loss: 0.6987 - accuracy: 0.8900 - val_loss: 0.6571 - val_accuracy: 0.8600\n",
      "Epoch 115/500\n",
      "1/1 - 0s - loss: 0.6953 - accuracy: 0.8800 - val_loss: 0.6535 - val_accuracy: 0.8600\n",
      "Epoch 116/500\n",
      "1/1 - 0s - loss: 0.6919 - accuracy: 0.8800 - val_loss: 0.6500 - val_accuracy: 0.8600\n",
      "Epoch 117/500\n",
      "1/1 - 0s - loss: 0.6885 - accuracy: 0.8800 - val_loss: 0.6465 - val_accuracy: 0.8600\n",
      "Epoch 118/500\n",
      "1/1 - 0s - loss: 0.6851 - accuracy: 0.8800 - val_loss: 0.6430 - val_accuracy: 0.8600\n",
      "Epoch 119/500\n",
      "1/1 - 0s - loss: 0.6818 - accuracy: 0.8800 - val_loss: 0.6395 - val_accuracy: 0.8600\n",
      "Epoch 120/500\n",
      "1/1 - 0s - loss: 0.6784 - accuracy: 0.8800 - val_loss: 0.6360 - val_accuracy: 0.8600\n",
      "Epoch 121/500\n",
      "1/1 - 0s - loss: 0.6751 - accuracy: 0.8800 - val_loss: 0.6326 - val_accuracy: 0.8800\n",
      "Epoch 122/500\n",
      "1/1 - 0s - loss: 0.6718 - accuracy: 0.8800 - val_loss: 0.6292 - val_accuracy: 0.8800\n",
      "Epoch 123/500\n",
      "1/1 - 0s - loss: 0.6685 - accuracy: 0.8800 - val_loss: 0.6258 - val_accuracy: 0.8800\n",
      "Epoch 124/500\n",
      "1/1 - 0s - loss: 0.6652 - accuracy: 0.8800 - val_loss: 0.6223 - val_accuracy: 0.8800\n",
      "Epoch 125/500\n",
      "1/1 - 0s - loss: 0.6619 - accuracy: 0.8800 - val_loss: 0.6189 - val_accuracy: 0.8800\n",
      "Epoch 126/500\n",
      "1/1 - 0s - loss: 0.6587 - accuracy: 0.8800 - val_loss: 0.6154 - val_accuracy: 0.8800\n",
      "Epoch 127/500\n",
      "1/1 - 0s - loss: 0.6555 - accuracy: 0.8800 - val_loss: 0.6121 - val_accuracy: 0.8800\n",
      "Epoch 128/500\n",
      "1/1 - 0s - loss: 0.6522 - accuracy: 0.8800 - val_loss: 0.6087 - val_accuracy: 0.8800\n",
      "Epoch 129/500\n",
      "1/1 - 0s - loss: 0.6491 - accuracy: 0.8800 - val_loss: 0.6053 - val_accuracy: 0.8800\n",
      "Epoch 130/500\n",
      "1/1 - 0s - loss: 0.6459 - accuracy: 0.8800 - val_loss: 0.6020 - val_accuracy: 0.8800\n",
      "Epoch 131/500\n",
      "1/1 - 0s - loss: 0.6427 - accuracy: 0.8800 - val_loss: 0.5987 - val_accuracy: 0.8800\n",
      "Epoch 132/500\n",
      "1/1 - 0s - loss: 0.6396 - accuracy: 0.8800 - val_loss: 0.5954 - val_accuracy: 0.8800\n",
      "Epoch 133/500\n",
      "1/1 - 0s - loss: 0.6365 - accuracy: 0.8800 - val_loss: 0.5922 - val_accuracy: 0.8800\n",
      "Epoch 134/500\n",
      "1/1 - 0s - loss: 0.6334 - accuracy: 0.8800 - val_loss: 0.5889 - val_accuracy: 0.8800\n",
      "Epoch 135/500\n",
      "1/1 - 0s - loss: 0.6302 - accuracy: 0.8800 - val_loss: 0.5857 - val_accuracy: 0.8800\n",
      "Epoch 136/500\n",
      "1/1 - 0s - loss: 0.6271 - accuracy: 0.8800 - val_loss: 0.5825 - val_accuracy: 0.8800\n",
      "Epoch 137/500\n",
      "1/1 - 0s - loss: 0.6240 - accuracy: 0.8800 - val_loss: 0.5794 - val_accuracy: 0.8800\n",
      "Epoch 138/500\n",
      "1/1 - 0s - loss: 0.6210 - accuracy: 0.8800 - val_loss: 0.5762 - val_accuracy: 0.8800\n",
      "Epoch 139/500\n",
      "1/1 - 0s - loss: 0.6179 - accuracy: 0.8800 - val_loss: 0.5731 - val_accuracy: 0.8800\n",
      "Epoch 140/500\n",
      "1/1 - 0s - loss: 0.6149 - accuracy: 0.8800 - val_loss: 0.5700 - val_accuracy: 0.8800\n",
      "Epoch 141/500\n",
      "1/1 - 0s - loss: 0.6118 - accuracy: 0.8800 - val_loss: 0.5669 - val_accuracy: 0.8800\n",
      "Epoch 142/500\n",
      "1/1 - 0s - loss: 0.6088 - accuracy: 0.8800 - val_loss: 0.5639 - val_accuracy: 0.8800\n",
      "Epoch 143/500\n",
      "1/1 - 0s - loss: 0.6059 - accuracy: 0.8800 - val_loss: 0.5609 - val_accuracy: 0.8800\n",
      "Epoch 144/500\n",
      "1/1 - 0s - loss: 0.6029 - accuracy: 0.8800 - val_loss: 0.5579 - val_accuracy: 0.8800\n",
      "Epoch 145/500\n",
      "1/1 - 0s - loss: 0.5999 - accuracy: 0.8800 - val_loss: 0.5549 - val_accuracy: 0.8800\n",
      "Epoch 146/500\n",
      "1/1 - 0s - loss: 0.5970 - accuracy: 0.8800 - val_loss: 0.5519 - val_accuracy: 0.8800\n",
      "Epoch 147/500\n",
      "1/1 - 0s - loss: 0.5941 - accuracy: 0.8800 - val_loss: 0.5490 - val_accuracy: 0.8800\n",
      "Epoch 148/500\n",
      "1/1 - 0s - loss: 0.5912 - accuracy: 0.8800 - val_loss: 0.5461 - val_accuracy: 0.8800\n",
      "Epoch 149/500\n",
      "1/1 - 0s - loss: 0.5884 - accuracy: 0.8800 - val_loss: 0.5432 - val_accuracy: 0.8800\n",
      "Epoch 150/500\n",
      "1/1 - 0s - loss: 0.5855 - accuracy: 0.8800 - val_loss: 0.5404 - val_accuracy: 0.8800\n",
      "Epoch 151/500\n",
      "1/1 - 0s - loss: 0.5827 - accuracy: 0.8800 - val_loss: 0.5376 - val_accuracy: 0.8800\n",
      "Epoch 152/500\n",
      "1/1 - 0s - loss: 0.5799 - accuracy: 0.8800 - val_loss: 0.5348 - val_accuracy: 0.8800\n",
      "Epoch 153/500\n",
      "1/1 - 0s - loss: 0.5771 - accuracy: 0.8800 - val_loss: 0.5320 - val_accuracy: 0.8800\n",
      "Epoch 154/500\n",
      "1/1 - 0s - loss: 0.5744 - accuracy: 0.8800 - val_loss: 0.5292 - val_accuracy: 0.8800\n",
      "Epoch 155/500\n",
      "1/1 - 0s - loss: 0.5716 - accuracy: 0.8800 - val_loss: 0.5265 - val_accuracy: 0.8800\n",
      "Epoch 156/500\n",
      "1/1 - 0s - loss: 0.5689 - accuracy: 0.8800 - val_loss: 0.5238 - val_accuracy: 0.8800\n",
      "Epoch 157/500\n",
      "1/1 - 0s - loss: 0.5662 - accuracy: 0.8800 - val_loss: 0.5211 - val_accuracy: 0.8800\n",
      "Epoch 158/500\n",
      "1/1 - 0s - loss: 0.5635 - accuracy: 0.8800 - val_loss: 0.5185 - val_accuracy: 0.8600\n",
      "Epoch 159/500\n",
      "1/1 - 0s - loss: 0.5609 - accuracy: 0.8800 - val_loss: 0.5158 - val_accuracy: 0.8600\n",
      "Epoch 160/500\n",
      "1/1 - 0s - loss: 0.5582 - accuracy: 0.8800 - val_loss: 0.5132 - val_accuracy: 0.8600\n",
      "Epoch 161/500\n",
      "1/1 - 0s - loss: 0.5556 - accuracy: 0.8800 - val_loss: 0.5107 - val_accuracy: 0.8600\n",
      "Epoch 162/500\n",
      "1/1 - 0s - loss: 0.5530 - accuracy: 0.8800 - val_loss: 0.5081 - val_accuracy: 0.8600\n",
      "Epoch 163/500\n",
      "1/1 - 0s - loss: 0.5505 - accuracy: 0.8800 - val_loss: 0.5056 - val_accuracy: 0.8600\n",
      "Epoch 164/500\n",
      "1/1 - 0s - loss: 0.5479 - accuracy: 0.8800 - val_loss: 0.5030 - val_accuracy: 0.8600\n",
      "Epoch 165/500\n",
      "1/1 - 0s - loss: 0.5454 - accuracy: 0.8800 - val_loss: 0.5006 - val_accuracy: 0.8600\n",
      "Epoch 166/500\n",
      "1/1 - 0s - loss: 0.5429 - accuracy: 0.8800 - val_loss: 0.4981 - val_accuracy: 0.8600\n",
      "Epoch 167/500\n",
      "1/1 - 0s - loss: 0.5404 - accuracy: 0.8800 - val_loss: 0.4956 - val_accuracy: 0.8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/500\n",
      "1/1 - 0s - loss: 0.5379 - accuracy: 0.8800 - val_loss: 0.4932 - val_accuracy: 0.8600\n",
      "Epoch 169/500\n",
      "1/1 - 0s - loss: 0.5355 - accuracy: 0.8800 - val_loss: 0.4908 - val_accuracy: 0.8600\n",
      "Epoch 170/500\n",
      "1/1 - 0s - loss: 0.5330 - accuracy: 0.8700 - val_loss: 0.4884 - val_accuracy: 0.8600\n",
      "Epoch 171/500\n",
      "1/1 - 0s - loss: 0.5306 - accuracy: 0.8700 - val_loss: 0.4861 - val_accuracy: 0.8600\n",
      "Epoch 172/500\n",
      "1/1 - 0s - loss: 0.5282 - accuracy: 0.8700 - val_loss: 0.4838 - val_accuracy: 0.8600\n",
      "Epoch 173/500\n",
      "1/1 - 0s - loss: 0.5258 - accuracy: 0.8700 - val_loss: 0.4814 - val_accuracy: 0.8600\n",
      "Epoch 174/500\n",
      "1/1 - 0s - loss: 0.5235 - accuracy: 0.8700 - val_loss: 0.4792 - val_accuracy: 0.8600\n",
      "Epoch 175/500\n",
      "1/1 - 0s - loss: 0.5211 - accuracy: 0.8700 - val_loss: 0.4769 - val_accuracy: 0.8600\n",
      "Epoch 176/500\n",
      "1/1 - 0s - loss: 0.5188 - accuracy: 0.8700 - val_loss: 0.4746 - val_accuracy: 0.8600\n",
      "Epoch 177/500\n",
      "1/1 - 0s - loss: 0.5164 - accuracy: 0.8700 - val_loss: 0.4724 - val_accuracy: 0.8600\n",
      "Epoch 178/500\n",
      "1/1 - 0s - loss: 0.5141 - accuracy: 0.8700 - val_loss: 0.4702 - val_accuracy: 0.8600\n",
      "Epoch 179/500\n",
      "1/1 - 0s - loss: 0.5118 - accuracy: 0.8700 - val_loss: 0.4680 - val_accuracy: 0.8600\n",
      "Epoch 180/500\n",
      "1/1 - 0s - loss: 0.5096 - accuracy: 0.8700 - val_loss: 0.4659 - val_accuracy: 0.8600\n",
      "Epoch 181/500\n",
      "1/1 - 0s - loss: 0.5073 - accuracy: 0.8700 - val_loss: 0.4637 - val_accuracy: 0.8600\n",
      "Epoch 182/500\n",
      "1/1 - 0s - loss: 0.5051 - accuracy: 0.8700 - val_loss: 0.4616 - val_accuracy: 0.8600\n",
      "Epoch 183/500\n",
      "1/1 - 0s - loss: 0.5029 - accuracy: 0.8700 - val_loss: 0.4595 - val_accuracy: 0.8600\n",
      "Epoch 184/500\n",
      "1/1 - 0s - loss: 0.5007 - accuracy: 0.8700 - val_loss: 0.4574 - val_accuracy: 0.8600\n",
      "Epoch 185/500\n",
      "1/1 - 0s - loss: 0.4985 - accuracy: 0.8700 - val_loss: 0.4553 - val_accuracy: 0.8600\n",
      "Epoch 186/500\n",
      "1/1 - 0s - loss: 0.4963 - accuracy: 0.8700 - val_loss: 0.4532 - val_accuracy: 0.8600\n",
      "Epoch 187/500\n",
      "1/1 - 0s - loss: 0.4942 - accuracy: 0.8700 - val_loss: 0.4512 - val_accuracy: 0.8600\n",
      "Epoch 188/500\n",
      "1/1 - 0s - loss: 0.4920 - accuracy: 0.8700 - val_loss: 0.4492 - val_accuracy: 0.8600\n",
      "Epoch 189/500\n",
      "1/1 - 0s - loss: 0.4899 - accuracy: 0.8700 - val_loss: 0.4472 - val_accuracy: 0.8600\n",
      "Epoch 190/500\n",
      "1/1 - 0s - loss: 0.4878 - accuracy: 0.8700 - val_loss: 0.4452 - val_accuracy: 0.8600\n",
      "Epoch 191/500\n",
      "1/1 - 0s - loss: 0.4857 - accuracy: 0.8700 - val_loss: 0.4433 - val_accuracy: 0.8600\n",
      "Epoch 192/500\n",
      "1/1 - 0s - loss: 0.4837 - accuracy: 0.8700 - val_loss: 0.4413 - val_accuracy: 0.8600\n",
      "Epoch 193/500\n",
      "1/1 - 0s - loss: 0.4816 - accuracy: 0.8700 - val_loss: 0.4394 - val_accuracy: 0.8600\n",
      "Epoch 194/500\n",
      "1/1 - 0s - loss: 0.4796 - accuracy: 0.8700 - val_loss: 0.4375 - val_accuracy: 0.8600\n",
      "Epoch 195/500\n",
      "1/1 - 0s - loss: 0.4776 - accuracy: 0.8700 - val_loss: 0.4356 - val_accuracy: 0.8600\n",
      "Epoch 196/500\n",
      "1/1 - 0s - loss: 0.4756 - accuracy: 0.8700 - val_loss: 0.4337 - val_accuracy: 0.8600\n",
      "Epoch 197/500\n",
      "1/1 - 0s - loss: 0.4736 - accuracy: 0.8700 - val_loss: 0.4318 - val_accuracy: 0.8600\n",
      "Epoch 198/500\n",
      "1/1 - 0s - loss: 0.4716 - accuracy: 0.8700 - val_loss: 0.4300 - val_accuracy: 0.8600\n",
      "Epoch 199/500\n",
      "1/1 - 0s - loss: 0.4697 - accuracy: 0.8700 - val_loss: 0.4282 - val_accuracy: 0.8600\n",
      "Epoch 200/500\n",
      "1/1 - 0s - loss: 0.4677 - accuracy: 0.8700 - val_loss: 0.4264 - val_accuracy: 0.8600\n",
      "Epoch 201/500\n",
      "1/1 - 0s - loss: 0.4658 - accuracy: 0.8700 - val_loss: 0.4246 - val_accuracy: 0.8600\n",
      "Epoch 202/500\n",
      "1/1 - 0s - loss: 0.4639 - accuracy: 0.8700 - val_loss: 0.4228 - val_accuracy: 0.8600\n",
      "Epoch 203/500\n",
      "1/1 - 0s - loss: 0.4620 - accuracy: 0.8700 - val_loss: 0.4210 - val_accuracy: 0.8600\n",
      "Epoch 204/500\n",
      "1/1 - 0s - loss: 0.4601 - accuracy: 0.8700 - val_loss: 0.4193 - val_accuracy: 0.8600\n",
      "Epoch 205/500\n",
      "1/1 - 0s - loss: 0.4583 - accuracy: 0.8700 - val_loss: 0.4176 - val_accuracy: 0.8600\n",
      "Epoch 206/500\n",
      "1/1 - 0s - loss: 0.4564 - accuracy: 0.8800 - val_loss: 0.4158 - val_accuracy: 0.8800\n",
      "Epoch 207/500\n",
      "1/1 - 0s - loss: 0.4546 - accuracy: 0.8800 - val_loss: 0.4141 - val_accuracy: 0.8800\n",
      "Epoch 208/500\n",
      "1/1 - 0s - loss: 0.4528 - accuracy: 0.8800 - val_loss: 0.4125 - val_accuracy: 0.8800\n",
      "Epoch 209/500\n",
      "1/1 - 0s - loss: 0.4510 - accuracy: 0.8800 - val_loss: 0.4108 - val_accuracy: 0.8800\n",
      "Epoch 210/500\n",
      "1/1 - 0s - loss: 0.4492 - accuracy: 0.8800 - val_loss: 0.4091 - val_accuracy: 0.8800\n",
      "Epoch 211/500\n",
      "1/1 - 0s - loss: 0.4474 - accuracy: 0.8800 - val_loss: 0.4075 - val_accuracy: 0.8800\n",
      "Epoch 212/500\n",
      "1/1 - 0s - loss: 0.4457 - accuracy: 0.8900 - val_loss: 0.4058 - val_accuracy: 0.8800\n",
      "Epoch 213/500\n",
      "1/1 - 0s - loss: 0.4439 - accuracy: 0.8900 - val_loss: 0.4042 - val_accuracy: 0.8800\n",
      "Epoch 214/500\n",
      "1/1 - 0s - loss: 0.4422 - accuracy: 0.8900 - val_loss: 0.4026 - val_accuracy: 0.8800\n",
      "Epoch 215/500\n",
      "1/1 - 0s - loss: 0.4405 - accuracy: 0.8900 - val_loss: 0.4010 - val_accuracy: 0.8800\n",
      "Epoch 216/500\n",
      "1/1 - 0s - loss: 0.4388 - accuracy: 0.8900 - val_loss: 0.3994 - val_accuracy: 0.8800\n",
      "Epoch 217/500\n",
      "1/1 - 0s - loss: 0.4371 - accuracy: 0.8900 - val_loss: 0.3978 - val_accuracy: 0.8800\n",
      "Epoch 218/500\n",
      "1/1 - 0s - loss: 0.4354 - accuracy: 0.8900 - val_loss: 0.3963 - val_accuracy: 0.8800\n",
      "Epoch 219/500\n",
      "1/1 - 0s - loss: 0.4337 - accuracy: 0.8900 - val_loss: 0.3947 - val_accuracy: 0.8800\n",
      "Epoch 220/500\n",
      "1/1 - 0s - loss: 0.4320 - accuracy: 0.8900 - val_loss: 0.3932 - val_accuracy: 0.8800\n",
      "Epoch 221/500\n",
      "1/1 - 0s - loss: 0.4304 - accuracy: 0.8900 - val_loss: 0.3917 - val_accuracy: 0.8800\n",
      "Epoch 222/500\n",
      "1/1 - 0s - loss: 0.4287 - accuracy: 0.8900 - val_loss: 0.3901 - val_accuracy: 0.8800\n",
      "Epoch 223/500\n",
      "1/1 - 0s - loss: 0.4271 - accuracy: 0.8900 - val_loss: 0.3887 - val_accuracy: 0.8800\n",
      "Epoch 224/500\n",
      "1/1 - 0s - loss: 0.4255 - accuracy: 0.8900 - val_loss: 0.3872 - val_accuracy: 0.8800\n",
      "Epoch 225/500\n",
      "1/1 - 0s - loss: 0.4239 - accuracy: 0.8900 - val_loss: 0.3857 - val_accuracy: 0.8800\n",
      "Epoch 226/500\n",
      "1/1 - 0s - loss: 0.4223 - accuracy: 0.8900 - val_loss: 0.3842 - val_accuracy: 0.8800\n",
      "Epoch 227/500\n",
      "1/1 - 0s - loss: 0.4207 - accuracy: 0.8900 - val_loss: 0.3828 - val_accuracy: 0.8800\n",
      "Epoch 228/500\n",
      "1/1 - 0s - loss: 0.4191 - accuracy: 0.9000 - val_loss: 0.3813 - val_accuracy: 0.8800\n",
      "Epoch 229/500\n",
      "1/1 - 0s - loss: 0.4176 - accuracy: 0.9000 - val_loss: 0.3799 - val_accuracy: 0.8800\n",
      "Epoch 230/500\n",
      "1/1 - 0s - loss: 0.4160 - accuracy: 0.9000 - val_loss: 0.3785 - val_accuracy: 0.8800\n",
      "Epoch 231/500\n",
      "1/1 - 0s - loss: 0.4145 - accuracy: 0.9000 - val_loss: 0.3771 - val_accuracy: 0.8800\n",
      "Epoch 232/500\n",
      "1/1 - 0s - loss: 0.4129 - accuracy: 0.9000 - val_loss: 0.3757 - val_accuracy: 0.8800\n",
      "Epoch 233/500\n",
      "1/1 - 0s - loss: 0.4114 - accuracy: 0.9000 - val_loss: 0.3743 - val_accuracy: 0.8800\n",
      "Epoch 234/500\n",
      "1/1 - 0s - loss: 0.4099 - accuracy: 0.9000 - val_loss: 0.3729 - val_accuracy: 0.8800\n",
      "Epoch 235/500\n",
      "1/1 - 0s - loss: 0.4084 - accuracy: 0.9000 - val_loss: 0.3715 - val_accuracy: 0.8800\n",
      "Epoch 236/500\n",
      "1/1 - 0s - loss: 0.4069 - accuracy: 0.9000 - val_loss: 0.3702 - val_accuracy: 0.8800\n",
      "Epoch 237/500\n",
      "1/1 - 0s - loss: 0.4055 - accuracy: 0.9000 - val_loss: 0.3688 - val_accuracy: 0.8800\n",
      "Epoch 238/500\n",
      "1/1 - 0s - loss: 0.4040 - accuracy: 0.9000 - val_loss: 0.3675 - val_accuracy: 0.8800\n",
      "Epoch 239/500\n",
      "1/1 - 0s - loss: 0.4026 - accuracy: 0.9000 - val_loss: 0.3662 - val_accuracy: 0.8800\n",
      "Epoch 240/500\n",
      "1/1 - 0s - loss: 0.4011 - accuracy: 0.9000 - val_loss: 0.3648 - val_accuracy: 0.8800\n",
      "Epoch 241/500\n",
      "1/1 - 0s - loss: 0.3997 - accuracy: 0.9000 - val_loss: 0.3635 - val_accuracy: 0.8800\n",
      "Epoch 242/500\n",
      "1/1 - 0s - loss: 0.3983 - accuracy: 0.9000 - val_loss: 0.3622 - val_accuracy: 0.8800\n",
      "Epoch 243/500\n",
      "1/1 - 0s - loss: 0.3968 - accuracy: 0.9000 - val_loss: 0.3609 - val_accuracy: 0.8800\n",
      "Epoch 244/500\n",
      "1/1 - 0s - loss: 0.3954 - accuracy: 0.9000 - val_loss: 0.3596 - val_accuracy: 0.8800\n",
      "Epoch 245/500\n",
      "1/1 - 0s - loss: 0.3940 - accuracy: 0.9000 - val_loss: 0.3584 - val_accuracy: 0.8800\n",
      "Epoch 246/500\n",
      "1/1 - 0s - loss: 0.3927 - accuracy: 0.9000 - val_loss: 0.3571 - val_accuracy: 0.8800\n",
      "Epoch 247/500\n",
      "1/1 - 0s - loss: 0.3913 - accuracy: 0.9000 - val_loss: 0.3558 - val_accuracy: 0.9000\n",
      "Epoch 248/500\n",
      "1/1 - 0s - loss: 0.3899 - accuracy: 0.9000 - val_loss: 0.3546 - val_accuracy: 0.9000\n",
      "Epoch 249/500\n",
      "1/1 - 0s - loss: 0.3886 - accuracy: 0.9000 - val_loss: 0.3534 - val_accuracy: 0.9000\n",
      "Epoch 250/500\n",
      "1/1 - 0s - loss: 0.3872 - accuracy: 0.9000 - val_loss: 0.3521 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/500\n",
      "1/1 - 0s - loss: 0.3859 - accuracy: 0.9000 - val_loss: 0.3509 - val_accuracy: 0.9000\n",
      "Epoch 252/500\n",
      "1/1 - 0s - loss: 0.3845 - accuracy: 0.9000 - val_loss: 0.3497 - val_accuracy: 0.9000\n",
      "Epoch 253/500\n",
      "1/1 - 0s - loss: 0.3832 - accuracy: 0.9000 - val_loss: 0.3485 - val_accuracy: 0.9000\n",
      "Epoch 254/500\n",
      "1/1 - 0s - loss: 0.3819 - accuracy: 0.9000 - val_loss: 0.3473 - val_accuracy: 0.9000\n",
      "Epoch 255/500\n",
      "1/1 - 0s - loss: 0.3806 - accuracy: 0.9000 - val_loss: 0.3461 - val_accuracy: 0.9000\n",
      "Epoch 256/500\n",
      "1/1 - 0s - loss: 0.3793 - accuracy: 0.9000 - val_loss: 0.3449 - val_accuracy: 0.9200\n",
      "Epoch 257/500\n",
      "1/1 - 0s - loss: 0.3780 - accuracy: 0.9000 - val_loss: 0.3437 - val_accuracy: 0.9200\n",
      "Epoch 258/500\n",
      "1/1 - 0s - loss: 0.3768 - accuracy: 0.9000 - val_loss: 0.3425 - val_accuracy: 0.9200\n",
      "Epoch 259/500\n",
      "1/1 - 0s - loss: 0.3755 - accuracy: 0.9000 - val_loss: 0.3414 - val_accuracy: 0.9200\n",
      "Epoch 260/500\n",
      "1/1 - 0s - loss: 0.3742 - accuracy: 0.9000 - val_loss: 0.3402 - val_accuracy: 0.9200\n",
      "Epoch 261/500\n",
      "1/1 - 0s - loss: 0.3730 - accuracy: 0.9000 - val_loss: 0.3391 - val_accuracy: 0.9200\n",
      "Epoch 262/500\n",
      "1/1 - 0s - loss: 0.3717 - accuracy: 0.9000 - val_loss: 0.3379 - val_accuracy: 0.9200\n",
      "Epoch 263/500\n",
      "1/1 - 0s - loss: 0.3705 - accuracy: 0.9000 - val_loss: 0.3368 - val_accuracy: 0.9200\n",
      "Epoch 264/500\n",
      "1/1 - 0s - loss: 0.3693 - accuracy: 0.9000 - val_loss: 0.3357 - val_accuracy: 0.9200\n",
      "Epoch 265/500\n",
      "1/1 - 0s - loss: 0.3681 - accuracy: 0.9000 - val_loss: 0.3346 - val_accuracy: 0.9200\n",
      "Epoch 266/500\n",
      "1/1 - 0s - loss: 0.3669 - accuracy: 0.9000 - val_loss: 0.3335 - val_accuracy: 0.9200\n",
      "Epoch 267/500\n",
      "1/1 - 0s - loss: 0.3657 - accuracy: 0.9100 - val_loss: 0.3324 - val_accuracy: 0.9200\n",
      "Epoch 268/500\n",
      "1/1 - 0s - loss: 0.3645 - accuracy: 0.9100 - val_loss: 0.3313 - val_accuracy: 0.9200\n",
      "Epoch 269/500\n",
      "1/1 - 0s - loss: 0.3633 - accuracy: 0.9100 - val_loss: 0.3302 - val_accuracy: 0.9200\n",
      "Epoch 270/500\n",
      "1/1 - 0s - loss: 0.3621 - accuracy: 0.9100 - val_loss: 0.3291 - val_accuracy: 0.9200\n",
      "Epoch 271/500\n",
      "1/1 - 0s - loss: 0.3609 - accuracy: 0.9100 - val_loss: 0.3280 - val_accuracy: 0.9200\n",
      "Epoch 272/500\n",
      "1/1 - 0s - loss: 0.3598 - accuracy: 0.9100 - val_loss: 0.3270 - val_accuracy: 0.9200\n",
      "Epoch 273/500\n",
      "1/1 - 0s - loss: 0.3586 - accuracy: 0.9100 - val_loss: 0.3259 - val_accuracy: 0.9200\n",
      "Epoch 274/500\n",
      "1/1 - 0s - loss: 0.3574 - accuracy: 0.9100 - val_loss: 0.3248 - val_accuracy: 0.9200\n",
      "Epoch 275/500\n",
      "1/1 - 0s - loss: 0.3563 - accuracy: 0.9100 - val_loss: 0.3238 - val_accuracy: 0.9200\n",
      "Epoch 276/500\n",
      "1/1 - 0s - loss: 0.3551 - accuracy: 0.9100 - val_loss: 0.3227 - val_accuracy: 0.9200\n",
      "Epoch 277/500\n",
      "1/1 - 0s - loss: 0.3540 - accuracy: 0.9100 - val_loss: 0.3217 - val_accuracy: 0.9200\n",
      "Epoch 278/500\n",
      "1/1 - 0s - loss: 0.3529 - accuracy: 0.9100 - val_loss: 0.3206 - val_accuracy: 0.9200\n",
      "Epoch 279/500\n",
      "1/1 - 0s - loss: 0.3518 - accuracy: 0.9100 - val_loss: 0.3196 - val_accuracy: 0.9200\n",
      "Epoch 280/500\n",
      "1/1 - 0s - loss: 0.3506 - accuracy: 0.9100 - val_loss: 0.3186 - val_accuracy: 0.9200\n",
      "Epoch 281/500\n",
      "1/1 - 0s - loss: 0.3495 - accuracy: 0.9100 - val_loss: 0.3176 - val_accuracy: 0.9200\n",
      "Epoch 282/500\n",
      "1/1 - 0s - loss: 0.3484 - accuracy: 0.9100 - val_loss: 0.3165 - val_accuracy: 0.9200\n",
      "Epoch 283/500\n",
      "1/1 - 0s - loss: 0.3473 - accuracy: 0.9100 - val_loss: 0.3155 - val_accuracy: 0.9200\n",
      "Epoch 284/500\n",
      "1/1 - 0s - loss: 0.3463 - accuracy: 0.9100 - val_loss: 0.3145 - val_accuracy: 0.9200\n",
      "Epoch 285/500\n",
      "1/1 - 0s - loss: 0.3452 - accuracy: 0.9100 - val_loss: 0.3135 - val_accuracy: 0.9200\n",
      "Epoch 286/500\n",
      "1/1 - 0s - loss: 0.3441 - accuracy: 0.9100 - val_loss: 0.3125 - val_accuracy: 0.9200\n",
      "Epoch 287/500\n",
      "1/1 - 0s - loss: 0.3430 - accuracy: 0.9100 - val_loss: 0.3115 - val_accuracy: 0.9200\n",
      "Epoch 288/500\n",
      "1/1 - 0s - loss: 0.3420 - accuracy: 0.9200 - val_loss: 0.3106 - val_accuracy: 0.9200\n",
      "Epoch 289/500\n",
      "1/1 - 0s - loss: 0.3409 - accuracy: 0.9200 - val_loss: 0.3096 - val_accuracy: 0.9200\n",
      "Epoch 290/500\n",
      "1/1 - 0s - loss: 0.3399 - accuracy: 0.9200 - val_loss: 0.3086 - val_accuracy: 0.9200\n",
      "Epoch 291/500\n",
      "1/1 - 0s - loss: 0.3388 - accuracy: 0.9200 - val_loss: 0.3076 - val_accuracy: 0.9200\n",
      "Epoch 292/500\n",
      "1/1 - 0s - loss: 0.3378 - accuracy: 0.9200 - val_loss: 0.3067 - val_accuracy: 0.9200\n",
      "Epoch 293/500\n",
      "1/1 - 0s - loss: 0.3367 - accuracy: 0.9200 - val_loss: 0.3057 - val_accuracy: 0.9200\n",
      "Epoch 294/500\n",
      "1/1 - 0s - loss: 0.3357 - accuracy: 0.9200 - val_loss: 0.3048 - val_accuracy: 0.9200\n",
      "Epoch 295/500\n",
      "1/1 - 0s - loss: 0.3347 - accuracy: 0.9200 - val_loss: 0.3038 - val_accuracy: 0.9200\n",
      "Epoch 296/500\n",
      "1/1 - 0s - loss: 0.3336 - accuracy: 0.9200 - val_loss: 0.3029 - val_accuracy: 0.9200\n",
      "Epoch 297/500\n",
      "1/1 - 0s - loss: 0.3326 - accuracy: 0.9200 - val_loss: 0.3019 - val_accuracy: 0.9200\n",
      "Epoch 298/500\n",
      "1/1 - 0s - loss: 0.3316 - accuracy: 0.9200 - val_loss: 0.3010 - val_accuracy: 0.9200\n",
      "Epoch 299/500\n",
      "1/1 - 0s - loss: 0.3306 - accuracy: 0.9200 - val_loss: 0.3001 - val_accuracy: 0.9200\n",
      "Epoch 300/500\n",
      "1/1 - 0s - loss: 0.3296 - accuracy: 0.9200 - val_loss: 0.2991 - val_accuracy: 0.9200\n",
      "Epoch 301/500\n",
      "1/1 - 0s - loss: 0.3286 - accuracy: 0.9200 - val_loss: 0.2982 - val_accuracy: 0.9200\n",
      "Epoch 302/500\n",
      "1/1 - 0s - loss: 0.3275 - accuracy: 0.9200 - val_loss: 0.2973 - val_accuracy: 0.9200\n",
      "Epoch 303/500\n",
      "1/1 - 0s - loss: 0.3266 - accuracy: 0.9200 - val_loss: 0.2964 - val_accuracy: 0.9200\n",
      "Epoch 304/500\n",
      "1/1 - 0s - loss: 0.3256 - accuracy: 0.9200 - val_loss: 0.2955 - val_accuracy: 0.9200\n",
      "Epoch 305/500\n",
      "1/1 - 0s - loss: 0.3246 - accuracy: 0.9200 - val_loss: 0.2945 - val_accuracy: 0.9200\n",
      "Epoch 306/500\n",
      "1/1 - 0s - loss: 0.3236 - accuracy: 0.9200 - val_loss: 0.2936 - val_accuracy: 0.9200\n",
      "Epoch 307/500\n",
      "1/1 - 0s - loss: 0.3226 - accuracy: 0.9200 - val_loss: 0.2927 - val_accuracy: 0.9200\n",
      "Epoch 308/500\n",
      "1/1 - 0s - loss: 0.3216 - accuracy: 0.9200 - val_loss: 0.2918 - val_accuracy: 0.9200\n",
      "Epoch 309/500\n",
      "1/1 - 0s - loss: 0.3207 - accuracy: 0.9200 - val_loss: 0.2910 - val_accuracy: 0.9200\n",
      "Epoch 310/500\n",
      "1/1 - 0s - loss: 0.3197 - accuracy: 0.9200 - val_loss: 0.2901 - val_accuracy: 0.9200\n",
      "Epoch 311/500\n",
      "1/1 - 0s - loss: 0.3187 - accuracy: 0.9200 - val_loss: 0.2892 - val_accuracy: 0.9200\n",
      "Epoch 312/500\n",
      "1/1 - 0s - loss: 0.3178 - accuracy: 0.9200 - val_loss: 0.2883 - val_accuracy: 0.9200\n",
      "Epoch 313/500\n",
      "1/1 - 0s - loss: 0.3168 - accuracy: 0.9200 - val_loss: 0.2874 - val_accuracy: 0.9200\n",
      "Epoch 314/500\n",
      "1/1 - 0s - loss: 0.3159 - accuracy: 0.9200 - val_loss: 0.2865 - val_accuracy: 0.9200\n",
      "Epoch 315/500\n",
      "1/1 - 0s - loss: 0.3149 - accuracy: 0.9200 - val_loss: 0.2857 - val_accuracy: 0.9200\n",
      "Epoch 316/500\n",
      "1/1 - 0s - loss: 0.3140 - accuracy: 0.9200 - val_loss: 0.2848 - val_accuracy: 0.9200\n",
      "Epoch 317/500\n",
      "1/1 - 0s - loss: 0.3130 - accuracy: 0.9200 - val_loss: 0.2839 - val_accuracy: 0.9200\n",
      "Epoch 318/500\n",
      "1/1 - 0s - loss: 0.3121 - accuracy: 0.9200 - val_loss: 0.2831 - val_accuracy: 0.9200\n",
      "Epoch 319/500\n",
      "1/1 - 0s - loss: 0.3112 - accuracy: 0.9200 - val_loss: 0.2822 - val_accuracy: 0.9200\n",
      "Epoch 320/500\n",
      "1/1 - 0s - loss: 0.3103 - accuracy: 0.9200 - val_loss: 0.2814 - val_accuracy: 0.9200\n",
      "Epoch 321/500\n",
      "1/1 - 0s - loss: 0.3093 - accuracy: 0.9200 - val_loss: 0.2805 - val_accuracy: 0.9200\n",
      "Epoch 322/500\n",
      "1/1 - 0s - loss: 0.3084 - accuracy: 0.9200 - val_loss: 0.2797 - val_accuracy: 0.9200\n",
      "Epoch 323/500\n",
      "1/1 - 0s - loss: 0.3075 - accuracy: 0.9200 - val_loss: 0.2788 - val_accuracy: 0.9200\n",
      "Epoch 324/500\n",
      "1/1 - 0s - loss: 0.3066 - accuracy: 0.9200 - val_loss: 0.2780 - val_accuracy: 0.9200\n",
      "Epoch 325/500\n",
      "1/1 - 0s - loss: 0.3057 - accuracy: 0.9200 - val_loss: 0.2772 - val_accuracy: 0.9200\n",
      "Epoch 326/500\n",
      "1/1 - 0s - loss: 0.3048 - accuracy: 0.9200 - val_loss: 0.2763 - val_accuracy: 0.9200\n",
      "Epoch 327/500\n",
      "1/1 - 0s - loss: 0.3039 - accuracy: 0.9200 - val_loss: 0.2755 - val_accuracy: 0.9200\n",
      "Epoch 328/500\n",
      "1/1 - 0s - loss: 0.3030 - accuracy: 0.9200 - val_loss: 0.2747 - val_accuracy: 0.9200\n",
      "Epoch 329/500\n",
      "1/1 - 0s - loss: 0.3021 - accuracy: 0.9200 - val_loss: 0.2739 - val_accuracy: 0.9200\n",
      "Epoch 330/500\n",
      "1/1 - 0s - loss: 0.3012 - accuracy: 0.9200 - val_loss: 0.2730 - val_accuracy: 0.9200\n",
      "Epoch 331/500\n",
      "1/1 - 0s - loss: 0.3003 - accuracy: 0.9200 - val_loss: 0.2722 - val_accuracy: 0.9200\n",
      "Epoch 332/500\n",
      "1/1 - 0s - loss: 0.2995 - accuracy: 0.9200 - val_loss: 0.2714 - val_accuracy: 0.9200\n",
      "Epoch 333/500\n",
      "1/1 - 0s - loss: 0.2986 - accuracy: 0.9200 - val_loss: 0.2706 - val_accuracy: 0.9200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/500\n",
      "1/1 - 0s - loss: 0.2977 - accuracy: 0.9300 - val_loss: 0.2698 - val_accuracy: 0.9200\n",
      "Epoch 335/500\n",
      "1/1 - 0s - loss: 0.2968 - accuracy: 0.9300 - val_loss: 0.2690 - val_accuracy: 0.9200\n",
      "Epoch 336/500\n",
      "1/1 - 0s - loss: 0.2960 - accuracy: 0.9300 - val_loss: 0.2682 - val_accuracy: 0.9200\n",
      "Epoch 337/500\n",
      "1/1 - 0s - loss: 0.2951 - accuracy: 0.9300 - val_loss: 0.2674 - val_accuracy: 0.9200\n",
      "Epoch 338/500\n",
      "1/1 - 0s - loss: 0.2943 - accuracy: 0.9300 - val_loss: 0.2666 - val_accuracy: 0.9200\n",
      "Epoch 339/500\n",
      "1/1 - 0s - loss: 0.2934 - accuracy: 0.9300 - val_loss: 0.2658 - val_accuracy: 0.9200\n",
      "Epoch 340/500\n",
      "1/1 - 0s - loss: 0.2926 - accuracy: 0.9300 - val_loss: 0.2650 - val_accuracy: 0.9200\n",
      "Epoch 341/500\n",
      "1/1 - 0s - loss: 0.2917 - accuracy: 0.9300 - val_loss: 0.2642 - val_accuracy: 0.9200\n",
      "Epoch 342/500\n",
      "1/1 - 0s - loss: 0.2909 - accuracy: 0.9300 - val_loss: 0.2635 - val_accuracy: 0.9200\n",
      "Epoch 343/500\n",
      "1/1 - 0s - loss: 0.2900 - accuracy: 0.9300 - val_loss: 0.2627 - val_accuracy: 0.9200\n",
      "Epoch 344/500\n",
      "1/1 - 0s - loss: 0.2892 - accuracy: 0.9300 - val_loss: 0.2619 - val_accuracy: 0.9200\n",
      "Epoch 345/500\n",
      "1/1 - 0s - loss: 0.2884 - accuracy: 0.9300 - val_loss: 0.2611 - val_accuracy: 0.9200\n",
      "Epoch 346/500\n",
      "1/1 - 0s - loss: 0.2876 - accuracy: 0.9300 - val_loss: 0.2604 - val_accuracy: 0.9200\n",
      "Epoch 347/500\n",
      "1/1 - 0s - loss: 0.2867 - accuracy: 0.9300 - val_loss: 0.2596 - val_accuracy: 0.9200\n",
      "Epoch 348/500\n",
      "1/1 - 0s - loss: 0.2859 - accuracy: 0.9300 - val_loss: 0.2589 - val_accuracy: 0.9200\n",
      "Epoch 349/500\n",
      "1/1 - 0s - loss: 0.2851 - accuracy: 0.9300 - val_loss: 0.2581 - val_accuracy: 0.9200\n",
      "Epoch 350/500\n",
      "1/1 - 0s - loss: 0.2843 - accuracy: 0.9300 - val_loss: 0.2573 - val_accuracy: 0.9400\n",
      "Epoch 351/500\n",
      "1/1 - 0s - loss: 0.2835 - accuracy: 0.9300 - val_loss: 0.2566 - val_accuracy: 0.9400\n",
      "Epoch 352/500\n",
      "1/1 - 0s - loss: 0.2827 - accuracy: 0.9300 - val_loss: 0.2558 - val_accuracy: 0.9400\n",
      "Epoch 353/500\n",
      "1/1 - 0s - loss: 0.2819 - accuracy: 0.9300 - val_loss: 0.2551 - val_accuracy: 0.9400\n",
      "Epoch 354/500\n",
      "1/1 - 0s - loss: 0.2811 - accuracy: 0.9300 - val_loss: 0.2544 - val_accuracy: 0.9400\n",
      "Epoch 355/500\n",
      "1/1 - 0s - loss: 0.2803 - accuracy: 0.9300 - val_loss: 0.2536 - val_accuracy: 0.9400\n",
      "Epoch 356/500\n",
      "1/1 - 0s - loss: 0.2795 - accuracy: 0.9300 - val_loss: 0.2529 - val_accuracy: 0.9400\n",
      "Epoch 357/500\n",
      "1/1 - 0s - loss: 0.2788 - accuracy: 0.9300 - val_loss: 0.2521 - val_accuracy: 0.9400\n",
      "Epoch 358/500\n",
      "1/1 - 0s - loss: 0.2780 - accuracy: 0.9300 - val_loss: 0.2514 - val_accuracy: 0.9400\n",
      "Epoch 359/500\n",
      "1/1 - 0s - loss: 0.2772 - accuracy: 0.9300 - val_loss: 0.2507 - val_accuracy: 0.9400\n",
      "Epoch 360/500\n",
      "1/1 - 0s - loss: 0.2764 - accuracy: 0.9300 - val_loss: 0.2500 - val_accuracy: 0.9400\n",
      "Epoch 361/500\n",
      "1/1 - 0s - loss: 0.2757 - accuracy: 0.9300 - val_loss: 0.2492 - val_accuracy: 0.9400\n",
      "Epoch 362/500\n",
      "1/1 - 0s - loss: 0.2749 - accuracy: 0.9300 - val_loss: 0.2485 - val_accuracy: 0.9400\n",
      "Epoch 363/500\n",
      "1/1 - 0s - loss: 0.2741 - accuracy: 0.9300 - val_loss: 0.2478 - val_accuracy: 0.9600\n",
      "Epoch 364/500\n",
      "1/1 - 0s - loss: 0.2734 - accuracy: 0.9300 - val_loss: 0.2471 - val_accuracy: 0.9600\n",
      "Epoch 365/500\n",
      "1/1 - 0s - loss: 0.2726 - accuracy: 0.9300 - val_loss: 0.2464 - val_accuracy: 0.9600\n",
      "Epoch 366/500\n",
      "1/1 - 0s - loss: 0.2719 - accuracy: 0.9300 - val_loss: 0.2456 - val_accuracy: 0.9600\n",
      "Epoch 367/500\n",
      "1/1 - 0s - loss: 0.2711 - accuracy: 0.9300 - val_loss: 0.2449 - val_accuracy: 0.9600\n",
      "Epoch 368/500\n",
      "1/1 - 0s - loss: 0.2704 - accuracy: 0.9300 - val_loss: 0.2442 - val_accuracy: 0.9600\n",
      "Epoch 369/500\n",
      "1/1 - 0s - loss: 0.2696 - accuracy: 0.9300 - val_loss: 0.2435 - val_accuracy: 0.9600\n",
      "Epoch 370/500\n",
      "1/1 - 0s - loss: 0.2689 - accuracy: 0.9300 - val_loss: 0.2428 - val_accuracy: 0.9600\n",
      "Epoch 371/500\n",
      "1/1 - 0s - loss: 0.2682 - accuracy: 0.9300 - val_loss: 0.2421 - val_accuracy: 0.9600\n",
      "Epoch 372/500\n",
      "1/1 - 0s - loss: 0.2674 - accuracy: 0.9300 - val_loss: 0.2414 - val_accuracy: 0.9600\n",
      "Epoch 373/500\n",
      "1/1 - 0s - loss: 0.2667 - accuracy: 0.9300 - val_loss: 0.2407 - val_accuracy: 0.9600\n",
      "Epoch 374/500\n",
      "1/1 - 0s - loss: 0.2660 - accuracy: 0.9300 - val_loss: 0.2400 - val_accuracy: 0.9600\n",
      "Epoch 375/500\n",
      "1/1 - 0s - loss: 0.2653 - accuracy: 0.9300 - val_loss: 0.2394 - val_accuracy: 0.9600\n",
      "Epoch 376/500\n",
      "1/1 - 0s - loss: 0.2645 - accuracy: 0.9300 - val_loss: 0.2387 - val_accuracy: 0.9600\n",
      "Epoch 377/500\n",
      "1/1 - 0s - loss: 0.2638 - accuracy: 0.9300 - val_loss: 0.2380 - val_accuracy: 0.9600\n",
      "Epoch 378/500\n",
      "1/1 - 0s - loss: 0.2631 - accuracy: 0.9300 - val_loss: 0.2373 - val_accuracy: 0.9600\n",
      "Epoch 379/500\n",
      "1/1 - 0s - loss: 0.2624 - accuracy: 0.9300 - val_loss: 0.2366 - val_accuracy: 0.9600\n",
      "Epoch 380/500\n",
      "1/1 - 0s - loss: 0.2617 - accuracy: 0.9300 - val_loss: 0.2359 - val_accuracy: 0.9600\n",
      "Epoch 381/500\n",
      "1/1 - 0s - loss: 0.2610 - accuracy: 0.9300 - val_loss: 0.2353 - val_accuracy: 0.9600\n",
      "Epoch 382/500\n",
      "1/1 - 0s - loss: 0.2603 - accuracy: 0.9300 - val_loss: 0.2346 - val_accuracy: 0.9600\n",
      "Epoch 383/500\n",
      "1/1 - 0s - loss: 0.2596 - accuracy: 0.9300 - val_loss: 0.2339 - val_accuracy: 0.9600\n",
      "Epoch 384/500\n",
      "1/1 - 0s - loss: 0.2589 - accuracy: 0.9300 - val_loss: 0.2333 - val_accuracy: 0.9400\n",
      "Epoch 385/500\n",
      "1/1 - 0s - loss: 0.2582 - accuracy: 0.9300 - val_loss: 0.2326 - val_accuracy: 0.9400\n",
      "Epoch 386/500\n",
      "1/1 - 0s - loss: 0.2575 - accuracy: 0.9300 - val_loss: 0.2319 - val_accuracy: 0.9400\n",
      "Epoch 387/500\n",
      "1/1 - 0s - loss: 0.2568 - accuracy: 0.9300 - val_loss: 0.2313 - val_accuracy: 0.9400\n",
      "Epoch 388/500\n",
      "1/1 - 0s - loss: 0.2561 - accuracy: 0.9300 - val_loss: 0.2306 - val_accuracy: 0.9400\n",
      "Epoch 389/500\n",
      "1/1 - 0s - loss: 0.2555 - accuracy: 0.9300 - val_loss: 0.2300 - val_accuracy: 0.9400\n",
      "Epoch 390/500\n",
      "1/1 - 0s - loss: 0.2548 - accuracy: 0.9300 - val_loss: 0.2293 - val_accuracy: 0.9400\n",
      "Epoch 391/500\n",
      "1/1 - 0s - loss: 0.2541 - accuracy: 0.9300 - val_loss: 0.2286 - val_accuracy: 0.9400\n",
      "Epoch 392/500\n",
      "1/1 - 0s - loss: 0.2534 - accuracy: 0.9300 - val_loss: 0.2280 - val_accuracy: 0.9400\n",
      "Epoch 393/500\n",
      "1/1 - 0s - loss: 0.2528 - accuracy: 0.9300 - val_loss: 0.2273 - val_accuracy: 0.9400\n",
      "Epoch 394/500\n",
      "1/1 - 0s - loss: 0.2521 - accuracy: 0.9300 - val_loss: 0.2267 - val_accuracy: 0.9400\n",
      "Epoch 395/500\n",
      "1/1 - 0s - loss: 0.2514 - accuracy: 0.9300 - val_loss: 0.2261 - val_accuracy: 0.9400\n",
      "Epoch 396/500\n",
      "1/1 - 0s - loss: 0.2508 - accuracy: 0.9300 - val_loss: 0.2254 - val_accuracy: 0.9400\n",
      "Epoch 397/500\n",
      "1/1 - 0s - loss: 0.2501 - accuracy: 0.9300 - val_loss: 0.2248 - val_accuracy: 0.9400\n",
      "Epoch 398/500\n",
      "1/1 - 0s - loss: 0.2495 - accuracy: 0.9300 - val_loss: 0.2241 - val_accuracy: 0.9400\n",
      "Epoch 399/500\n",
      "1/1 - 0s - loss: 0.2488 - accuracy: 0.9300 - val_loss: 0.2235 - val_accuracy: 0.9600\n",
      "Epoch 400/500\n",
      "1/1 - 0s - loss: 0.2481 - accuracy: 0.9300 - val_loss: 0.2228 - val_accuracy: 0.9600\n",
      "Epoch 401/500\n",
      "1/1 - 0s - loss: 0.2475 - accuracy: 0.9300 - val_loss: 0.2222 - val_accuracy: 0.9600\n",
      "Epoch 402/500\n",
      "1/1 - 0s - loss: 0.2468 - accuracy: 0.9300 - val_loss: 0.2216 - val_accuracy: 0.9600\n",
      "Epoch 403/500\n",
      "1/1 - 0s - loss: 0.2462 - accuracy: 0.9300 - val_loss: 0.2209 - val_accuracy: 0.9600\n",
      "Epoch 404/500\n",
      "1/1 - 0s - loss: 0.2456 - accuracy: 0.9300 - val_loss: 0.2203 - val_accuracy: 0.9600\n",
      "Epoch 405/500\n",
      "1/1 - 0s - loss: 0.2449 - accuracy: 0.9300 - val_loss: 0.2197 - val_accuracy: 0.9600\n",
      "Epoch 406/500\n",
      "1/1 - 0s - loss: 0.2443 - accuracy: 0.9300 - val_loss: 0.2191 - val_accuracy: 0.9600\n",
      "Epoch 407/500\n",
      "1/1 - 0s - loss: 0.2436 - accuracy: 0.9300 - val_loss: 0.2184 - val_accuracy: 0.9600\n",
      "Epoch 408/500\n",
      "1/1 - 0s - loss: 0.2430 - accuracy: 0.9300 - val_loss: 0.2178 - val_accuracy: 0.9600\n",
      "Epoch 409/500\n",
      "1/1 - 0s - loss: 0.2424 - accuracy: 0.9300 - val_loss: 0.2172 - val_accuracy: 0.9600\n",
      "Epoch 410/500\n",
      "1/1 - 0s - loss: 0.2417 - accuracy: 0.9300 - val_loss: 0.2166 - val_accuracy: 0.9600\n",
      "Epoch 411/500\n",
      "1/1 - 0s - loss: 0.2411 - accuracy: 0.9300 - val_loss: 0.2159 - val_accuracy: 0.9600\n",
      "Epoch 412/500\n",
      "1/1 - 0s - loss: 0.2405 - accuracy: 0.9300 - val_loss: 0.2153 - val_accuracy: 0.9600\n",
      "Epoch 413/500\n",
      "1/1 - 0s - loss: 0.2399 - accuracy: 0.9300 - val_loss: 0.2147 - val_accuracy: 0.9600\n",
      "Epoch 414/500\n",
      "1/1 - 0s - loss: 0.2392 - accuracy: 0.9300 - val_loss: 0.2141 - val_accuracy: 0.9600\n",
      "Epoch 415/500\n",
      "1/1 - 0s - loss: 0.2386 - accuracy: 0.9300 - val_loss: 0.2135 - val_accuracy: 0.9600\n",
      "Epoch 416/500\n",
      "1/1 - 0s - loss: 0.2380 - accuracy: 0.9300 - val_loss: 0.2129 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/500\n",
      "1/1 - 0s - loss: 0.2374 - accuracy: 0.9300 - val_loss: 0.2123 - val_accuracy: 0.9600\n",
      "Epoch 418/500\n",
      "1/1 - 0s - loss: 0.2368 - accuracy: 0.9300 - val_loss: 0.2117 - val_accuracy: 0.9600\n",
      "Epoch 419/500\n",
      "1/1 - 0s - loss: 0.2362 - accuracy: 0.9300 - val_loss: 0.2111 - val_accuracy: 0.9600\n",
      "Epoch 420/500\n",
      "1/1 - 0s - loss: 0.2356 - accuracy: 0.9300 - val_loss: 0.2105 - val_accuracy: 0.9600\n",
      "Epoch 421/500\n",
      "1/1 - 0s - loss: 0.2350 - accuracy: 0.9300 - val_loss: 0.2099 - val_accuracy: 0.9600\n",
      "Epoch 422/500\n",
      "1/1 - 0s - loss: 0.2344 - accuracy: 0.9300 - val_loss: 0.2093 - val_accuracy: 0.9600\n",
      "Epoch 423/500\n",
      "1/1 - 0s - loss: 0.2338 - accuracy: 0.9300 - val_loss: 0.2087 - val_accuracy: 0.9600\n",
      "Epoch 424/500\n",
      "1/1 - 0s - loss: 0.2332 - accuracy: 0.9300 - val_loss: 0.2081 - val_accuracy: 0.9600\n",
      "Epoch 425/500\n",
      "1/1 - 0s - loss: 0.2326 - accuracy: 0.9300 - val_loss: 0.2075 - val_accuracy: 0.9600\n",
      "Epoch 426/500\n",
      "1/1 - 0s - loss: 0.2320 - accuracy: 0.9300 - val_loss: 0.2069 - val_accuracy: 0.9600\n",
      "Epoch 427/500\n",
      "1/1 - 0s - loss: 0.2314 - accuracy: 0.9300 - val_loss: 0.2063 - val_accuracy: 0.9600\n",
      "Epoch 428/500\n",
      "1/1 - 0s - loss: 0.2308 - accuracy: 0.9300 - val_loss: 0.2057 - val_accuracy: 0.9600\n",
      "Epoch 429/500\n",
      "1/1 - 0s - loss: 0.2302 - accuracy: 0.9300 - val_loss: 0.2051 - val_accuracy: 0.9600\n",
      "Epoch 430/500\n",
      "1/1 - 0s - loss: 0.2296 - accuracy: 0.9300 - val_loss: 0.2045 - val_accuracy: 0.9600\n",
      "Epoch 431/500\n",
      "1/1 - 0s - loss: 0.2290 - accuracy: 0.9300 - val_loss: 0.2039 - val_accuracy: 0.9600\n",
      "Epoch 432/500\n",
      "1/1 - 0s - loss: 0.2284 - accuracy: 0.9300 - val_loss: 0.2033 - val_accuracy: 0.9600\n",
      "Epoch 433/500\n",
      "1/1 - 0s - loss: 0.2278 - accuracy: 0.9300 - val_loss: 0.2028 - val_accuracy: 0.9600\n",
      "Epoch 434/500\n",
      "1/1 - 0s - loss: 0.2273 - accuracy: 0.9300 - val_loss: 0.2022 - val_accuracy: 0.9600\n",
      "Epoch 435/500\n",
      "1/1 - 0s - loss: 0.2267 - accuracy: 0.9300 - val_loss: 0.2016 - val_accuracy: 0.9600\n",
      "Epoch 436/500\n",
      "1/1 - 0s - loss: 0.2261 - accuracy: 0.9300 - val_loss: 0.2010 - val_accuracy: 0.9600\n",
      "Epoch 437/500\n",
      "1/1 - 0s - loss: 0.2255 - accuracy: 0.9300 - val_loss: 0.2005 - val_accuracy: 0.9600\n",
      "Epoch 438/500\n",
      "1/1 - 0s - loss: 0.2250 - accuracy: 0.9300 - val_loss: 0.1999 - val_accuracy: 0.9600\n",
      "Epoch 439/500\n",
      "1/1 - 0s - loss: 0.2244 - accuracy: 0.9300 - val_loss: 0.1993 - val_accuracy: 0.9600\n",
      "Epoch 440/500\n",
      "1/1 - 0s - loss: 0.2238 - accuracy: 0.9300 - val_loss: 0.1987 - val_accuracy: 0.9600\n",
      "Epoch 441/500\n",
      "1/1 - 0s - loss: 0.2233 - accuracy: 0.9300 - val_loss: 0.1982 - val_accuracy: 0.9600\n",
      "Epoch 442/500\n",
      "1/1 - 0s - loss: 0.2227 - accuracy: 0.9300 - val_loss: 0.1976 - val_accuracy: 0.9600\n",
      "Epoch 443/500\n",
      "1/1 - 0s - loss: 0.2221 - accuracy: 0.9300 - val_loss: 0.1970 - val_accuracy: 0.9600\n",
      "Epoch 444/500\n",
      "1/1 - 0s - loss: 0.2216 - accuracy: 0.9300 - val_loss: 0.1965 - val_accuracy: 0.9600\n",
      "Epoch 445/500\n",
      "1/1 - 0s - loss: 0.2210 - accuracy: 0.9300 - val_loss: 0.1959 - val_accuracy: 0.9600\n",
      "Epoch 446/500\n",
      "1/1 - 0s - loss: 0.2205 - accuracy: 0.9300 - val_loss: 0.1953 - val_accuracy: 0.9600\n",
      "Epoch 447/500\n",
      "1/1 - 0s - loss: 0.2199 - accuracy: 0.9300 - val_loss: 0.1948 - val_accuracy: 0.9600\n",
      "Epoch 448/500\n",
      "1/1 - 0s - loss: 0.2194 - accuracy: 0.9300 - val_loss: 0.1942 - val_accuracy: 0.9600\n",
      "Epoch 449/500\n",
      "1/1 - 0s - loss: 0.2188 - accuracy: 0.9300 - val_loss: 0.1937 - val_accuracy: 0.9600\n",
      "Epoch 450/500\n",
      "1/1 - 0s - loss: 0.2183 - accuracy: 0.9300 - val_loss: 0.1931 - val_accuracy: 0.9600\n",
      "Epoch 451/500\n",
      "1/1 - 0s - loss: 0.2177 - accuracy: 0.9400 - val_loss: 0.1925 - val_accuracy: 0.9600\n",
      "Epoch 452/500\n",
      "1/1 - 0s - loss: 0.2172 - accuracy: 0.9400 - val_loss: 0.1920 - val_accuracy: 0.9600\n",
      "Epoch 453/500\n",
      "1/1 - 0s - loss: 0.2167 - accuracy: 0.9400 - val_loss: 0.1914 - val_accuracy: 0.9600\n",
      "Epoch 454/500\n",
      "1/1 - 0s - loss: 0.2161 - accuracy: 0.9400 - val_loss: 0.1908 - val_accuracy: 0.9600\n",
      "Epoch 455/500\n",
      "1/1 - 0s - loss: 0.2156 - accuracy: 0.9400 - val_loss: 0.1903 - val_accuracy: 0.9600\n",
      "Epoch 456/500\n",
      "1/1 - 0s - loss: 0.2150 - accuracy: 0.9400 - val_loss: 0.1897 - val_accuracy: 0.9600\n",
      "Epoch 457/500\n",
      "1/1 - 0s - loss: 0.2145 - accuracy: 0.9400 - val_loss: 0.1892 - val_accuracy: 0.9600\n",
      "Epoch 458/500\n",
      "1/1 - 0s - loss: 0.2140 - accuracy: 0.9400 - val_loss: 0.1886 - val_accuracy: 0.9600\n",
      "Epoch 459/500\n",
      "1/1 - 0s - loss: 0.2134 - accuracy: 0.9400 - val_loss: 0.1881 - val_accuracy: 0.9600\n",
      "Epoch 460/500\n",
      "1/1 - 0s - loss: 0.2129 - accuracy: 0.9400 - val_loss: 0.1875 - val_accuracy: 0.9600\n",
      "Epoch 461/500\n",
      "1/1 - 0s - loss: 0.2124 - accuracy: 0.9400 - val_loss: 0.1870 - val_accuracy: 0.9600\n",
      "Epoch 462/500\n",
      "1/1 - 0s - loss: 0.2119 - accuracy: 0.9400 - val_loss: 0.1864 - val_accuracy: 0.9600\n",
      "Epoch 463/500\n",
      "1/1 - 0s - loss: 0.2113 - accuracy: 0.9400 - val_loss: 0.1859 - val_accuracy: 0.9800\n",
      "Epoch 464/500\n",
      "1/1 - 0s - loss: 0.2108 - accuracy: 0.9400 - val_loss: 0.1854 - val_accuracy: 0.9800\n",
      "Epoch 465/500\n",
      "1/1 - 0s - loss: 0.2103 - accuracy: 0.9400 - val_loss: 0.1849 - val_accuracy: 0.9800\n",
      "Epoch 466/500\n",
      "1/1 - 0s - loss: 0.2098 - accuracy: 0.9400 - val_loss: 0.1843 - val_accuracy: 0.9800\n",
      "Epoch 467/500\n",
      "1/1 - 0s - loss: 0.2093 - accuracy: 0.9400 - val_loss: 0.1838 - val_accuracy: 0.9800\n",
      "Epoch 468/500\n",
      "1/1 - 0s - loss: 0.2088 - accuracy: 0.9400 - val_loss: 0.1833 - val_accuracy: 0.9800\n",
      "Epoch 469/500\n",
      "1/1 - 0s - loss: 0.2082 - accuracy: 0.9400 - val_loss: 0.1828 - val_accuracy: 0.9800\n",
      "Epoch 470/500\n",
      "1/1 - 0s - loss: 0.2077 - accuracy: 0.9400 - val_loss: 0.1822 - val_accuracy: 0.9800\n",
      "Epoch 471/500\n",
      "1/1 - 0s - loss: 0.2072 - accuracy: 0.9400 - val_loss: 0.1817 - val_accuracy: 0.9800\n",
      "Epoch 472/500\n",
      "1/1 - 0s - loss: 0.2067 - accuracy: 0.9400 - val_loss: 0.1812 - val_accuracy: 0.9800\n",
      "Epoch 473/500\n",
      "1/1 - 0s - loss: 0.2062 - accuracy: 0.9400 - val_loss: 0.1807 - val_accuracy: 0.9800\n",
      "Epoch 474/500\n",
      "1/1 - 0s - loss: 0.2057 - accuracy: 0.9400 - val_loss: 0.1802 - val_accuracy: 0.9800\n",
      "Epoch 475/500\n",
      "1/1 - 0s - loss: 0.2052 - accuracy: 0.9400 - val_loss: 0.1797 - val_accuracy: 0.9800\n",
      "Epoch 476/500\n",
      "1/1 - 0s - loss: 0.2047 - accuracy: 0.9400 - val_loss: 0.1792 - val_accuracy: 0.9800\n",
      "Epoch 477/500\n",
      "1/1 - 0s - loss: 0.2042 - accuracy: 0.9400 - val_loss: 0.1786 - val_accuracy: 0.9800\n",
      "Epoch 478/500\n",
      "1/1 - 0s - loss: 0.2037 - accuracy: 0.9400 - val_loss: 0.1781 - val_accuracy: 0.9800\n",
      "Epoch 479/500\n",
      "1/1 - 0s - loss: 0.2032 - accuracy: 0.9400 - val_loss: 0.1776 - val_accuracy: 0.9800\n",
      "Epoch 480/500\n",
      "1/1 - 0s - loss: 0.2027 - accuracy: 0.9400 - val_loss: 0.1771 - val_accuracy: 0.9800\n",
      "Epoch 481/500\n",
      "1/1 - 0s - loss: 0.2022 - accuracy: 0.9400 - val_loss: 0.1766 - val_accuracy: 0.9800\n",
      "Epoch 482/500\n",
      "1/1 - 0s - loss: 0.2017 - accuracy: 0.9400 - val_loss: 0.1761 - val_accuracy: 0.9800\n",
      "Epoch 483/500\n",
      "1/1 - 0s - loss: 0.2013 - accuracy: 0.9400 - val_loss: 0.1756 - val_accuracy: 0.9800\n",
      "Epoch 484/500\n",
      "1/1 - 0s - loss: 0.2008 - accuracy: 0.9400 - val_loss: 0.1751 - val_accuracy: 0.9800\n",
      "Epoch 485/500\n",
      "1/1 - 0s - loss: 0.2003 - accuracy: 0.9400 - val_loss: 0.1746 - val_accuracy: 0.9800\n",
      "Epoch 486/500\n",
      "1/1 - 0s - loss: 0.1998 - accuracy: 0.9400 - val_loss: 0.1742 - val_accuracy: 0.9800\n",
      "Epoch 487/500\n",
      "1/1 - 0s - loss: 0.1993 - accuracy: 0.9400 - val_loss: 0.1737 - val_accuracy: 0.9800\n",
      "Epoch 488/500\n",
      "1/1 - 0s - loss: 0.1988 - accuracy: 0.9400 - val_loss: 0.1732 - val_accuracy: 0.9800\n",
      "Epoch 489/500\n",
      "1/1 - 0s - loss: 0.1984 - accuracy: 0.9400 - val_loss: 0.1727 - val_accuracy: 0.9800\n",
      "Epoch 490/500\n",
      "1/1 - 0s - loss: 0.1979 - accuracy: 0.9400 - val_loss: 0.1722 - val_accuracy: 0.9800\n",
      "Epoch 491/500\n",
      "1/1 - 0s - loss: 0.1974 - accuracy: 0.9400 - val_loss: 0.1717 - val_accuracy: 0.9800\n",
      "Epoch 492/500\n",
      "1/1 - 0s - loss: 0.1969 - accuracy: 0.9400 - val_loss: 0.1713 - val_accuracy: 0.9800\n",
      "Epoch 493/500\n",
      "1/1 - 0s - loss: 0.1965 - accuracy: 0.9400 - val_loss: 0.1708 - val_accuracy: 0.9800\n",
      "Epoch 494/500\n",
      "1/1 - 0s - loss: 0.1960 - accuracy: 0.9400 - val_loss: 0.1703 - val_accuracy: 0.9800\n",
      "Epoch 495/500\n",
      "1/1 - 0s - loss: 0.1955 - accuracy: 0.9400 - val_loss: 0.1698 - val_accuracy: 0.9800\n",
      "Epoch 496/500\n",
      "1/1 - 0s - loss: 0.1951 - accuracy: 0.9400 - val_loss: 0.1694 - val_accuracy: 0.9800\n",
      "Epoch 497/500\n",
      "1/1 - 0s - loss: 0.1946 - accuracy: 0.9400 - val_loss: 0.1689 - val_accuracy: 0.9800\n",
      "Epoch 498/500\n",
      "1/1 - 0s - loss: 0.1942 - accuracy: 0.9400 - val_loss: 0.1684 - val_accuracy: 0.9800\n",
      "Epoch 499/500\n",
      "1/1 - 0s - loss: 0.1937 - accuracy: 0.9400 - val_loss: 0.1680 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500\n",
      "1/1 - 0s - loss: 0.1932 - accuracy: 0.9400 - val_loss: 0.1675 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "model_reg.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "mlp_reg = model_reg.fit(X_train, y_train, batch_size=256, epochs=500, verbose=2,\n",
    "                        validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Curves')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(mlp_reg.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(mlp_reg.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy Curves')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(mlp_reg.history['accuracy'],'r',linewidth=3.0)\n",
    "plt.plot(mlp_reg.history['val_accuracy'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(4, 10) dtype=float32, numpy=\n",
       " array([[ 0.29831377,  0.24537544, -0.19258662, -0.6373028 ,  0.6154362 ,\n",
       "          0.11215325, -0.06159195,  0.38772926,  0.02359573, -0.6285936 ],\n",
       "        [-0.87288517,  0.33479422, -0.01659078,  0.5814331 , -0.4722265 ,\n",
       "         -0.27157295, -0.16337338, -0.33601767, -0.24443968,  0.7356963 ],\n",
       "        [ 0.47690177, -0.90398836,  0.6604855 , -0.7043333 ,  0.7724138 ,\n",
       "          0.26498777,  0.8282656 ,  0.5795836 ,  0.520994  ,  0.2495573 ],\n",
       "        [-0.5584169 , -0.13076496, -0.1276727 , -0.47336   ,  0.87499994,\n",
       "          0.7145068 ,  0.7171009 ,  0.48489603,  1.040268  , -0.21894304]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.5421501 ,  0.4224352 ,  0.43091357,  0.1248324 ,  0.32836297,\n",
       "        -0.33151704,  0.03200141, -0.26332   , -0.40631425,  0.24870813],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(10, 3) dtype=float32, numpy=\n",
       " array([[ 0.01610134,  0.8758589 , -0.03362449],\n",
       "        [ 0.2012136 , -0.57971215, -0.907511  ],\n",
       "        [-0.8734446 ,  0.48054495, -0.15847026],\n",
       "        [ 0.19222528, -0.8703484 , -0.04452304],\n",
       "        [-0.82861555, -0.18868636, -0.14002383],\n",
       "        [ 0.07056215, -0.36701477,  0.3204249 ],\n",
       "        [-0.5550278 , -0.3239363 ,  0.81041485],\n",
       "        [-0.33863354, -0.7714281 , -0.0586197 ],\n",
       "        [ 0.00696508, -0.39352235,  0.42027888],\n",
       "        [ 0.49752763, -0.61887664, -0.8455093 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(3,) dtype=float32, numpy=array([-0.2691689 ,  0.47432816, -0.43345395], dtype=float32)>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating  population with random weights\n",
    "population_size = 50\n",
    "# W1 size(4,10)  ip-hidden\n",
    "# W2 size (10,)  act hidden\n",
    "# W3 size (10,3) hidden-output\n",
    "# W4 size (3) output act\n",
    "\n",
    "# generate this for 50 population\n",
    "W1_shape = K.eval(model_reg.weights[0]).shape\n",
    "W2_shape = K.eval(model_reg.weights[1]).shape\n",
    "W3_shape = K.eval(model_reg.weights[2]).shape\n",
    "W4_shape = K.eval(model_reg.weights[3]).shape\n",
    "\n",
    "W1 =np.random.randn(W1_shape[0],W1_shape[1])\n",
    "W2 =np.random.randn(W2_shape[0])\n",
    "W3 =np.random.randn(W3_shape[0],W3_shape[1])\n",
    "W4 =np.random.randn(W4_shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(4, 10) dtype=float32, numpy=\n",
       " array([[ 0.29831377,  0.24537544, -0.19258662, -0.6373028 ,  0.6154362 ,\n",
       "          0.11215325, -0.06159195,  0.38772926,  0.02359573, -0.6285936 ],\n",
       "        [-0.87288517,  0.33479422, -0.01659078,  0.5814331 , -0.4722265 ,\n",
       "         -0.27157295, -0.16337338, -0.33601767, -0.24443968,  0.7356963 ],\n",
       "        [ 0.47690177, -0.90398836,  0.6604855 , -0.7043333 ,  0.7724138 ,\n",
       "          0.26498777,  0.8282656 ,  0.5795836 ,  0.520994  ,  0.2495573 ],\n",
       "        [-0.5584169 , -0.13076496, -0.1276727 , -0.47336   ,  0.87499994,\n",
       "          0.7145068 ,  0.7171009 ,  0.48489603,  1.040268  , -0.21894304]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(10,) dtype=float32, numpy=\n",
       " array([ 0.5421501 ,  0.4224352 ,  0.43091357,  0.1248324 ,  0.32836297,\n",
       "        -0.33151704,  0.03200141, -0.26332   , -0.40631425,  0.24870813],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(10, 3) dtype=float32, numpy=\n",
       " array([[ 0.01610134,  0.8758589 , -0.03362449],\n",
       "        [ 0.2012136 , -0.57971215, -0.907511  ],\n",
       "        [-0.8734446 ,  0.48054495, -0.15847026],\n",
       "        [ 0.19222528, -0.8703484 , -0.04452304],\n",
       "        [-0.82861555, -0.18868636, -0.14002383],\n",
       "        [ 0.07056215, -0.36701477,  0.3204249 ],\n",
       "        [-0.5550278 , -0.3239363 ,  0.81041485],\n",
       "        [-0.33863354, -0.7714281 , -0.0586197 ],\n",
       "        [ 0.00696508, -0.39352235,  0.42027888],\n",
       "        [ 0.49752763, -0.61887664, -0.8455093 ]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(3,) dtype=float32, numpy=array([-0.2691689 ,  0.47432816, -0.43345395], dtype=float32)>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.36849003e-01  1.26902560e+00 -6.91289588e-01 -5.53292129e-05\n",
      "  -3.62304335e-01  1.27797367e+00  1.82979179e-01 -7.40429941e-01\n",
      "   2.86372357e-01 -5.85593841e-01]\n",
      " [ 3.37886351e-02  4.31273528e-01  4.29850243e-01 -8.86522904e-01\n",
      "   1.12596252e+00  8.37089186e-01  8.88771618e-01 -2.99764752e-01\n",
      "   8.26769525e-01 -9.11494480e-01]\n",
      " [-1.55940424e-01  2.11339421e+00 -6.30530884e-01  5.32695338e-01\n",
      "  -1.20227323e-01  5.21606551e-01  7.39627229e-01  7.06712375e-01\n",
      "   1.07024502e+00 -7.10283797e-01]\n",
      " [ 3.03604436e-01 -5.66768155e-01 -4.19950950e-01  2.32195935e-01\n",
      "   3.40304467e-02  1.29245663e+00 -2.80747186e-01  9.78545814e-01\n",
      "   2.11994669e+00 -1.01493960e+00]]\n",
      "[ 0.27103922 -0.85651362  0.36303727  1.13536195  0.61389003  0.4897511\n",
      " -0.07256113  1.34402783  0.48973843  0.68489055]\n",
      "[[ 0.57830588  1.3500025  -0.68072659]\n",
      " [ 2.2609074   1.11510376 -1.14985753]\n",
      " [-0.26636969 -0.53838633 -0.79494148]\n",
      " [-0.04286696  0.79803742 -1.97593453]\n",
      " [-1.79427372  1.18759659 -0.38410847]\n",
      " [ 0.35869261 -1.00038196 -1.99690863]\n",
      " [-2.87651034  0.20744391  0.04623269]\n",
      " [-1.48665662  2.67106912  1.98049103]\n",
      " [ 0.04610384  0.68068044  0.75602593]\n",
      " [ 0.14545684  0.75694316  0.54363554]]\n",
      "[-0.13818245 -0.27846312  0.12433064]\n"
     ]
    }
   ],
   "source": [
    "print(W1)\n",
    "print(W2)\n",
    "print(W3)\n",
    "print(W4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gene:\n",
    "    def __init__(self,W1_shape,W2_shape,W3_shape,W4_shape):\n",
    "        self.W1 =np.random.randn(W1_shape[0],W1_shape[1])\n",
    "        self.W2 =np.random.randn(W2_shape[0])\n",
    "        self.W3 =np.random.randn(W3_shape[0],W3_shape[1])\n",
    "        self.W4 =np.random.randn(W4_shape[0])\n",
    "        \n",
    "    def show_gene(self):\n",
    "        print(self.W1)\n",
    "        print(self.W2)\n",
    "        print(self.W3)\n",
    "        print(self.W4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class genetic_algo:\n",
    "    def __init__(self,pop_size):\n",
    "        self.popualtion_size = pop_size\n",
    "        self.gene = []\n",
    "        self.fitness_score = {}\n",
    "        \n",
    "    # generate population\n",
    "    def generate_population(self,W1_shape,W2_shape,W3_shape,W4_shape):\n",
    "        for i in range(self.popualtion_size):\n",
    "            self.gene.append(Gene(W1_shape,W2_shape,W3_shape,W4_shape))\n",
    "    \n",
    "    # set weight\n",
    "    def set_model_weights(self,model1,W1,W2,W3,W4):\n",
    "        model1.layers[0].set_weights([W1,W2])\n",
    "        model1.layers[1].set_weights([W3,W4])\n",
    "        return model1\n",
    "        \n",
    "    #Foward propagate function\n",
    "    def forward_propagate(self,model,X_train,y_train):\n",
    "        \n",
    "        for pop in range(self.popualtion_size):\n",
    "            model = self.set_model_weights(model,self.gene[pop].W1,self.gene[pop].W2,self.gene[pop].W3,self.gene[pop].W4)\n",
    "            step=0\n",
    "            total_loss = 0\n",
    "            loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "            for x_batch_train, y_batch_train in zip(X_train,y_train):\n",
    "                logits = model(x_batch_train.reshape(1,-1))\n",
    "                y_true = y_batch_train\n",
    "                count=0\n",
    "                for i in range(len(y_true)):\n",
    "                    if y_true[i]==1:\n",
    "                        break\n",
    "                    count+=1\n",
    "                loss_value = loss_fn(count, logits)\n",
    "                total_loss+=loss_value\n",
    "                #print(\"Training loss at step %d: %.4f\" % (step, float(loss_value)))\n",
    "                step+=1\n",
    "            avg_loss = total_loss/len(X_train)\n",
    "            print(\" Gene %d: Average trainning loss is %f\"%(pop,avg_loss))\n",
    "            self.fitness_score[pop]=avg_loss\n",
    "        return self.fitness_score\n",
    "    \n",
    "    #Natural_Selection\n",
    "    def natural_selection(self,selection_percent,size):\n",
    "        fitness = dict(sorted(self.fitness_score.items(), key=lambda item: item[1]))\n",
    "        fitness_items = fitness.items()\n",
    "        selection_range = int(selection_percent/100*size)\n",
    "        selected_dict = list(fitness_items)[:selection_range]\n",
    "        selected_dict = dict(selected_dict)\n",
    "        return selected_dict # best genes are selected\n",
    "    \n",
    "    #breed and mutation\n",
    "    def breed(self,parent1,parent2,max_mutation,mutation_rate):\n",
    "        off_spring = Gene(parent1.W1.shape,parent1.W2.shape,parent1.W3.shape,parent1.W4.shape)\n",
    "        \n",
    "        if(random.randrange(0,max_mutation) > mutation_rate):\n",
    "            off_spring.W1 = parent1.W1 if random.randrange(0,10) < 5 else parent2.W1\n",
    "        else:\n",
    "            off_spring.W1 = np.random.randn(parent1.W1.shape[0],parent1.W1.shape[1])\n",
    "        \n",
    "        if(random.randrange(0,max_mutation) > mutation_rate):\n",
    "            off_spring.W2 = parent1.W2 if random.randrange(0,10) < 5 else parent2.W2\n",
    "        else:\n",
    "            off_spring.W2 = np.random.randn(parent1.W2.shape[0])\n",
    "        \n",
    "        if(random.randrange(0,max_mutation) > mutation_rate):\n",
    "            off_spring.W3 = parent1.W3 if random.randrange(0,10) < 5 else parent2.W3\n",
    "        else:\n",
    "            off_spring.W3 = np.random.randn(parent1.W3.shape[0],parent1.W3.shape[1])\n",
    "        \n",
    "        if(random.randrange(0,max_mutation) > mutation_rate):\n",
    "            off_spring.W4 = parent1.W4 if random.randrange(0,10) < 5 else parent2.W4\n",
    "        else:\n",
    "            off_spring.W4 = np.random.randn(parent1.W4.shape[0])\n",
    "            \n",
    "        return off_spring\n",
    "       \n",
    "    #CrossOver\n",
    "    def cross_over(self,max_mutation,mutation_rate,selection_percent,size):\n",
    "        Prev_gen_gene = self.gene.copy()\n",
    "        self.gene.clear()\n",
    "        print(\"population of gene {}\".format(len(Prev_gen_gene)))\n",
    "        selected_dict = self.natural_selection(selection_percent,size)\n",
    "        selected_dict = list(selected_dict)\n",
    "        self.gene.append(Prev_gen_gene[selected_dict[0]])\n",
    "        self.gene.append(Prev_gen_gene[selected_dict[1]])\n",
    "        #loop \n",
    "        print(len(selected_dict))\n",
    "        print(selected_dict)\n",
    "        for i in range(len(selected_dict)-1):# breed A with B and B with A\n",
    "            off_spring1 = self.breed(Prev_gen_gene[selected_dict[i]],Prev_gen_gene[selected_dict[i+1]],max_mutation,mutation_rate)\n",
    "            self.gene.append(off_spring1)\n",
    "            off_spring2 = self.breed(Prev_gen_gene[selected_dict[i+1]],Prev_gen_gene[selected_dict[i]],max_mutation,mutation_rate)\n",
    "            self.gene.append(off_spring2)\n",
    "        self.gene = self.gene[:self.popualtion_size]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Population = genetic_algo(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Population.generate_population(W1_shape,W2_shape,W3_shape,W4_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gene 0: Average trainning loss is 1.265371\n",
      " Gene 1: Average trainning loss is 1.283510\n",
      " Gene 2: Average trainning loss is 1.123171\n",
      " Gene 3: Average trainning loss is 1.400596\n",
      " Gene 4: Average trainning loss is 1.035272\n",
      " Gene 5: Average trainning loss is 0.924012\n",
      " Gene 6: Average trainning loss is 0.821239\n",
      " Gene 7: Average trainning loss is 1.121156\n",
      " Gene 8: Average trainning loss is 1.029275\n",
      " Gene 9: Average trainning loss is 1.404532\n",
      " Gene 10: Average trainning loss is 1.253167\n",
      " Gene 11: Average trainning loss is 1.341634\n",
      " Gene 12: Average trainning loss is 1.248224\n",
      " Gene 13: Average trainning loss is 1.215573\n",
      " Gene 14: Average trainning loss is 0.939744\n",
      " Gene 15: Average trainning loss is 1.221041\n",
      " Gene 16: Average trainning loss is 1.148075\n",
      " Gene 17: Average trainning loss is 1.482049\n",
      " Gene 18: Average trainning loss is 1.511175\n",
      " Gene 19: Average trainning loss is 1.168677\n",
      " Gene 20: Average trainning loss is 1.084181\n",
      " Gene 21: Average trainning loss is 1.095547\n",
      " Gene 22: Average trainning loss is 1.045411\n",
      " Gene 23: Average trainning loss is 1.017978\n",
      " Gene 24: Average trainning loss is 0.999531\n",
      " Gene 25: Average trainning loss is 1.071618\n",
      " Gene 26: Average trainning loss is 1.207570\n",
      " Gene 27: Average trainning loss is 0.970545\n",
      " Gene 28: Average trainning loss is 1.103932\n",
      " Gene 29: Average trainning loss is 0.927583\n",
      " Gene 30: Average trainning loss is 1.231681\n",
      " Gene 31: Average trainning loss is 1.055970\n",
      " Gene 32: Average trainning loss is 1.180955\n",
      " Gene 33: Average trainning loss is 1.043154\n",
      " Gene 34: Average trainning loss is 0.976779\n",
      " Gene 35: Average trainning loss is 1.211662\n",
      " Gene 36: Average trainning loss is 1.405619\n",
      " Gene 37: Average trainning loss is 1.172838\n",
      " Gene 38: Average trainning loss is 1.185431\n",
      " Gene 39: Average trainning loss is 1.232455\n",
      " Gene 40: Average trainning loss is 1.257193\n",
      " Gene 41: Average trainning loss is 1.163137\n",
      " Gene 42: Average trainning loss is 1.204552\n",
      " Gene 43: Average trainning loss is 1.244224\n",
      " Gene 44: Average trainning loss is 1.255601\n",
      " Gene 45: Average trainning loss is 0.957906\n",
      " Gene 46: Average trainning loss is 1.119926\n",
      " Gene 47: Average trainning loss is 1.154574\n",
      " Gene 48: Average trainning loss is 0.992746\n",
      " Gene 49: Average trainning loss is 1.237367\n"
     ]
    }
   ],
   "source": [
    "fitness = Population.forward_propagate(model_reg,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population of gene 50\n",
      "25\n",
      "[6, 5, 29, 14, 45, 27, 34, 48, 24, 23, 8, 4, 33, 22, 31, 25, 20, 21, 28, 46, 7, 2, 16, 47, 41]\n"
     ]
    }
   ],
   "source": [
    "Population.cross_over(1000,30,50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gene 0: Average trainning loss is 0.924012\n",
      " Gene 1: Average trainning loss is 0.821239\n",
      " Gene 2: Average trainning loss is 0.989655\n",
      " Gene 3: Average trainning loss is 1.357813\n",
      " Gene 4: Average trainning loss is 1.156560\n",
      " Gene 5: Average trainning loss is 1.001222\n",
      " Gene 6: Average trainning loss is 0.949032\n",
      " Gene 7: Average trainning loss is 1.007726\n",
      " Gene 8: Average trainning loss is 0.883263\n",
      " Gene 9: Average trainning loss is 0.869706\n",
      " Gene 10: Average trainning loss is 1.040940\n",
      " Gene 11: Average trainning loss is 1.380239\n",
      " Gene 12: Average trainning loss is 1.115199\n",
      " Gene 13: Average trainning loss is 1.029501\n",
      " Gene 14: Average trainning loss is 1.147799\n",
      " Gene 15: Average trainning loss is 1.285402\n",
      " Gene 16: Average trainning loss is 1.017978\n",
      " Gene 17: Average trainning loss is 1.115316\n",
      " Gene 18: Average trainning loss is 0.974905\n",
      " Gene 19: Average trainning loss is 0.929000\n",
      " Gene 20: Average trainning loss is 1.297628\n",
      " Gene 21: Average trainning loss is 1.160333\n",
      " Gene 22: Average trainning loss is 1.379399\n",
      " Gene 23: Average trainning loss is 1.255054\n",
      " Gene 24: Average trainning loss is 1.045411\n",
      " Gene 25: Average trainning loss is 1.262740\n",
      " Gene 26: Average trainning loss is 1.248885\n",
      " Gene 27: Average trainning loss is 1.248885\n",
      " Gene 28: Average trainning loss is 1.065753\n",
      " Gene 29: Average trainning loss is 1.099218\n",
      " Gene 30: Average trainning loss is 0.922046\n",
      " Gene 31: Average trainning loss is 1.049243\n",
      " Gene 32: Average trainning loss is 1.248966\n",
      " Gene 33: Average trainning loss is 1.172768\n",
      " Gene 34: Average trainning loss is 1.188498\n",
      " Gene 35: Average trainning loss is 1.158966\n",
      " Gene 36: Average trainning loss is 1.097933\n",
      " Gene 37: Average trainning loss is 1.239923\n",
      " Gene 38: Average trainning loss is 1.396729\n",
      " Gene 39: Average trainning loss is 1.440463\n",
      " Gene 40: Average trainning loss is 1.176480\n",
      " Gene 41: Average trainning loss is 0.960290\n",
      " Gene 42: Average trainning loss is 0.820444\n",
      " Gene 43: Average trainning loss is 1.030253\n",
      " Gene 44: Average trainning loss is 1.426785\n",
      " Gene 45: Average trainning loss is 1.203180\n",
      " Gene 46: Average trainning loss is 1.001268\n",
      " Gene 47: Average trainning loss is 1.182332\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-0bd8db29bafe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPopulation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_reg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-458ba523aa63>\u001b[0m in \u001b[0;36mforward_propagate\u001b[1;34m(self, model, X_train, y_train)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpop\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopualtion_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgene\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgene\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgene\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgene\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "fitness = Population.forward_propagate(model_reg,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness = dict(sorted(fitness.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_list = list(Population.natural_selection(50,Population.popualtion_size))\n",
    "s_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offspring = Population.breed(Population.gene[s_list[0]],Population.gene[s_list[1]],1000,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offspring.show_gene()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Population.set_model_weights(model_reg,offspring.W1,offspring.W2,offspring.W3,offspring.W4)\n",
    "step=0\n",
    "total_loss = 0\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "for x_batch_train, y_batch_train in zip(X_train,y_train):\n",
    "    logits = model(x_batch_train.reshape(1,-1))\n",
    "    y_true = y_batch_train\n",
    "    count=0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i]==1:\n",
    "            break\n",
    "        count+=1\n",
    "    loss_value = loss_fn(count, logits)\n",
    "    total_loss+=loss_value\n",
    "    #print(\"Training loss at step %d: %.4f\" % (step, float(loss_value)))\n",
    "    step+=1\n",
    "avg_loss = total_loss/len(X_train)\n",
    "print(\" Gene 1: Average trainning loss is %f\"%(avg_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
